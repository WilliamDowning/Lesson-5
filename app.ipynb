{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n",
    "if iskaggle: path - Path('../input/titanic')\n",
    "else:\n",
    "    path = Path('titanic')\n",
    "    if not path.exists():\n",
    "        import zipfile,kaggle\n",
    "        kaggle.api.competition_download_cli(str(path))\n",
    "        zipfile.ZipFile(f'{path}.zip').extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "np.set_printoptions(linewidth=140)\n",
    "torch.set_printoptions(linewidth=140, sci_mode=False, edgeitems=7)\n",
    "pd.set_option('display.width', 140)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Up Our Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                               Name     Sex   Age  SibSp  Parch            Ticket  \\\n",
       "0              1         0       3                            Braund, Mr. Owen Harris    male  22.0      1      0         A/5 21171   \n",
       "1              2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1      0          PC 17599   \n",
       "2              3         1       3                             Heikkinen, Miss. Laina  female  26.0      0      0  STON/O2. 3101282   \n",
       "3              4         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0            113803   \n",
       "4              5         0       3                           Allen, Mr. William Henry    male  35.0      0      0            373450   \n",
       "..           ...       ...     ...                                                ...     ...   ...    ...    ...               ...   \n",
       "886          887         0       2                              Montvila, Rev. Juozas    male  27.0      0      0            211536   \n",
       "887          888         1       1                       Graham, Miss. Margaret Edith  female  19.0      0      0            112053   \n",
       "888          889         0       3           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1      2        W./C. 6607   \n",
       "889          890         1       1                              Behr, Mr. Karl Howell    male  26.0      0      0            111369   \n",
       "890          891         0       3                                Dooley, Mr. Patrick    male  32.0      0      0            370376   \n",
       "\n",
       "        Fare Cabin Embarked  \n",
       "0     7.2500   NaN        S  \n",
       "1    71.2833   C85        C  \n",
       "2     7.9250   NaN        S  \n",
       "3    53.1000  C123        S  \n",
       "4     8.0500   NaN        S  \n",
       "..       ...   ...      ...  \n",
       "886  13.0000   NaN        S  \n",
       "887  30.0000   B42        S  \n",
       "888  23.4500   NaN        S  \n",
       "889  30.0000  C148        C  \n",
       "890   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('titanic')\n",
    "df = pd.read_csv(path/'train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId                      1\n",
       "Survived                       0.0\n",
       "Pclass                         3.0\n",
       "Name           Abbing, Mr. Anthony\n",
       "Sex                           male\n",
       "Age                           24.0\n",
       "SibSp                          0.0\n",
       "Parch                          0.0\n",
       "Ticket                        1601\n",
       "Fare                          8.05\n",
       "Cabin                      B96 B98\n",
       "Embarked                         S\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modes = df.mode().iloc[0]\n",
    "modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(modes, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Cabin          0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>28.566970</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.199572</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp       Parch        Fare\n",
       "count   891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000\n",
       "mean    446.000000    0.383838    2.308642   28.566970    0.523008    0.381594   32.204208\n",
       "std     257.353842    0.486592    0.836071   13.199572    1.102743    0.806057   49.693429\n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%     223.500000    0.000000    2.000000   22.000000    0.000000    0.000000    7.910400\n",
       "50%     446.000000    0.000000    3.000000   24.000000    0.000000    0.000000   14.454200\n",
       "75%     668.500000    1.000000    3.000000   35.000000    1.000000    0.000000   31.000000\n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=(np.number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Fare'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LogFare'] = np.log(df['Fare'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['LogFare'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the purpose of Pclass column (They seem to be categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pclasses = sorted(df.Pclass.unique())\n",
    "pclasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe shows all non-numeric variables, their count, how many unique ones there are and the top and frequency of the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>681</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>1601</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>7</td>\n",
       "      <td>691</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Name   Sex Ticket    Cabin Embarked\n",
       "count                   891   891    891      891      891\n",
       "unique                  891     2    681      147        3\n",
       "top     Dooley, Mr. Patrick  male   1601  B96 B98        S\n",
       "freq                      1   577      7      691      646"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=[object])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to be able to multiply these non-numeric columns by coefficients so we need to make dummy variables of true (1) or false (0) boolean columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'LogFare', 'Sex_female', 'Sex_male',\n",
       "       'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df, columns=[\"Sex\", \"Pclass\", \"Embarked\"], dtype=float)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex_male  Sex_female  Pclass_1  Pclass_2  Pclass_3  Embarked_C  Embarked_Q  Embarked_S\n",
       "0       1.0         0.0       0.0       0.0       1.0         0.0         0.0         1.0\n",
       "1       0.0         1.0       1.0       0.0       0.0         1.0         0.0         0.0\n",
       "2       0.0         1.0       0.0       0.0       1.0         0.0         0.0         1.0\n",
       "3       0.0         1.0       1.0       0.0       0.0         0.0         0.0         1.0\n",
       "4       1.0         0.0       0.0       0.0       1.0         0.0         0.0         1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "added_cols = ['Sex_male', 'Sex_female', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
    "df[added_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a tensor matrix of the dependent variable, whether the entry has survived or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "t_dep = tensor(df.Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates another tensor matrix of the independent variables that we will test with to predict if the entry survived or not. It includes the rows we had to clean such as LogFare(formally Fare), 'Sex_male' and 'Sex_female'(formally Sex), 'Pclass_1', 'Pclass_2' and 'Pclass_3'(formally known as Pclass) and finally 'Embarked_C', 'Embarked_Q' and 'Embarked_S'(formally Embarked)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22.0000,  1.0000,  0.0000,  2.1102,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [38.0000,  1.0000,  0.0000,  4.2806,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
       "        [26.0000,  0.0000,  0.0000,  2.1889,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [35.0000,  1.0000,  0.0000,  3.9908,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [35.0000,  0.0000,  0.0000,  2.2028,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [24.0000,  0.0000,  0.0000,  2.2469,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000],\n",
       "        [54.0000,  0.0000,  0.0000,  3.9677,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
       "        ...,\n",
       "        [25.0000,  0.0000,  0.0000,  2.0857,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [39.0000,  0.0000,  5.0000,  3.4054,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000],\n",
       "        [27.0000,  0.0000,  0.0000,  2.6391,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [19.0000,  0.0000,  0.0000,  3.4340,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [24.0000,  1.0000,  2.0000,  3.1966,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [26.0000,  0.0000,  0.0000,  3.4340,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
       "        [32.0000,  0.0000,  0.0000,  2.1691,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indep_cols = ['Age','SibSp','Parch','LogFare'] + added_cols\n",
    "\n",
    "t_indep = tensor(df[indep_cols].values, dtype=torch.float)\n",
    "t_indep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shows you how many rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([891, 12])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tells you the number of (rank) dimensions the tensor has, a vector is rank 1, a matrix is rank 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t_indep.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up a linear model\n",
    "\n",
    "We need to multiply our rows of data by coefficients that are randomized and made for each column:  \n",
    "<img src=\"images/Example-of-a-linear-ML-model-The-outcome-y-is-predicted-by-the-multiplication-of-feature.png\"\n",
    "     alt=\"linear ML model outcome\" />    \n",
    "\n",
    "1 Set the seed for the tensor to simulate creating some \"random\" number generation.  \n",
    "2 Grabbing the number of coefficients we need to multiply against our matrix.  \n",
    "3 Generate n_coeff amount of random coefficients between 0 and 1. We subtract 0.5 to center the values so max = 0.5 and min = -0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(442) #1\n",
    "\n",
    "n_coeff = t_indep.shape[1] #2\n",
    "coeffs = torch.rand(n_coeff) - 0.5 #3\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then multiply our matrix to our vector via element-wise multiplication through broadcasting and the use of (*) symbol:\n",
    "  \n",
    "<img src=\"images/Numpy-Broadcasting.png\"\n",
    "     alt=\"linear ML model outcome\" />\n",
    "\n",
    "\n",
    "Seeing that our Matrix was 861 rows and 12 columns. Our Vector matches to have 12 coefficients that will broadcast that:\n",
    "\n",
    "- For every coefficient in the vector, each row of the matrix will be mutiplied by that same coefficient based on the index of that column.\n",
    "\n",
    "- Our vector becomes a matrix with a repeating values for over 861 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-10.1838,   0.1386,   0.0000,  -0.4772,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],\n",
       "        [-17.5902,   0.1386,   0.0000,  -0.9681,  -0.0000,  -0.3147,   0.4876,   0.0000,   0.0000,  -0.4392,   0.0000,   0.0000],\n",
       "        [-12.0354,   0.0000,   0.0000,  -0.4950,  -0.0000,  -0.3147,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],\n",
       "        [-16.2015,   0.1386,   0.0000,  -0.9025,  -0.0000,  -0.3147,   0.4876,   0.0000,   0.0000,  -0.0000,   0.0000,   0.3625],\n",
       "        [-16.2015,   0.0000,   0.0000,  -0.4982,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],\n",
       "        [-11.1096,   0.0000,   0.0000,  -0.5081,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.2103,   0.0000],\n",
       "        [-24.9966,   0.0000,   0.0000,  -0.8973,  -0.2632,  -0.0000,   0.4876,   0.0000,   0.0000,  -0.0000,   0.0000,   0.3625],\n",
       "        ...,\n",
       "        [-11.5725,   0.0000,   0.0000,  -0.4717,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],\n",
       "        [-18.0531,   0.0000,   1.2045,  -0.7701,  -0.0000,  -0.3147,   0.0000,   0.0000,   0.2799,  -0.0000,   0.2103,   0.0000],\n",
       "        [-12.4983,   0.0000,   0.0000,  -0.5968,  -0.2632,  -0.0000,   0.0000,   0.3136,   0.0000,  -0.0000,   0.0000,   0.3625],\n",
       "        [ -8.7951,   0.0000,   0.0000,  -0.7766,  -0.0000,  -0.3147,   0.4876,   0.0000,   0.0000,  -0.0000,   0.0000,   0.3625],\n",
       "        [-11.1096,   0.1386,   0.4818,  -0.7229,  -0.0000,  -0.3147,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],\n",
       "        [-12.0354,   0.0000,   0.0000,  -0.7766,  -0.2632,  -0.0000,   0.4876,   0.0000,   0.0000,  -0.4392,   0.0000,   0.0000],\n",
       "        [-14.8128,   0.0000,   0.0000,  -0.4905,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.2103,   0.0000]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep*coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the first column above has a big outputs compared to its other columns, this means when it will be multiplied by its coefficient that it will be significantly impacted differently than the other columns. To fix that we are going to normalize the values by dividing by the maximum value.  \n",
    "\n",
    "We pass dim = 0 within max to specify that we want the maximum found within the rows and not the columns which would be dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals,indices = t_indep.max(dim = 0)\n",
    "t_indep = t_indep / vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now see that the values are evened out across all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1273,  0.0173,  0.0000, -0.0765, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.2199,  0.0173,  0.0000, -0.1551, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.4392,  0.0000,  0.0000],\n",
       "        [-0.1504,  0.0000,  0.0000, -0.0793, -0.0000, -0.3147,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.2025,  0.0173,  0.0000, -0.1446, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.2025,  0.0000,  0.0000, -0.0798, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.1389,  0.0000,  0.0000, -0.0814, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.2103,  0.0000],\n",
       "        [-0.3125,  0.0000,  0.0000, -0.1438, -0.2632, -0.0000,  0.4876,  0.0000,  0.0000, -0.0000,  0.0000,  0.3625],\n",
       "        ...,\n",
       "        [-0.1447,  0.0000,  0.0000, -0.0756, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.2257,  0.0000,  0.2008, -0.1234, -0.0000, -0.3147,  0.0000,  0.0000,  0.2799, -0.0000,  0.2103,  0.0000],\n",
       "        [-0.1562,  0.0000,  0.0000, -0.0956, -0.2632, -0.0000,  0.0000,  0.3136,  0.0000, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.1099,  0.0000,  0.0000, -0.1244, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.1389,  0.0173,  0.0803, -0.1158, -0.0000, -0.3147,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.1504,  0.0000,  0.0000, -0.1244, -0.2632, -0.0000,  0.4876,  0.0000,  0.0000, -0.4392,  0.0000,  0.0000],\n",
       "        [-0.1852,  0.0000,  0.0000, -0.0786, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.2103,  0.0000]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep*coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "axis = 1 specfies that we want to add up our multipied matrix by the columns rather than the rows.  \n",
    "\n",
    "This is suppose to help determine our predictions as each coefficient in each row is an independent weight that will determine what the dependent variable will result in. For this case its whether or not they survived the titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = (t_indep*coeffs).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first ten rows of the prediction values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1927, -0.6239,  0.0979,  0.2056,  0.0968,  0.0066,  0.1306,  0.3476,  0.1613, -0.6285])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These initial values are just random and by no means have any ground for being accurate, but they are a starting point to begin the method of gradient descent.  \n",
    "\n",
    "Here's what that would look like:  \n",
    "\n",
    "<img src=\"images/Gradient_Descent.png\"\n",
    "     alt=\"linear ML model outcome\" />  \n",
    "\n",
    "\n",
    "Cost simply put is performance while weight is the what coefficients you placed for each column that help determine the prediction.  \n",
    "\n",
    "To determine how much we incrementally step by, we need to create a loss function that calculates how much do we need to alter certain coefficients to hopefully improve the cost.  \n",
    "\n",
    "One of these ways is through mean absolute value of the calculated prediction - actual prediction as we see below\n",
    "\n",
    "loss is the calculation of how close our model was to the target. In this case if the person survived or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5382)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.abs(preds-t_dep).mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create functions to automate and repeat our steps  \n",
    "\n",
    "\n",
    "These are past code snippets we ran, but now reusable since placed in a function block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_preds(coeffs, indeps): return (indeps*coeffs).sum(axis=1)\n",
    "def calc_loss(coeffs, indeps, deps): return torch.abs(calc_preds(coeffs, indeps)-deps).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing a gradient descent step  \n",
    "\n",
    "Where does derivatives fit into our idea of gradient descent? It helps to determine in which direction the incremental step will go in. Based on last image above, it makes it seem obvious to know which direction to go in, but not all gradient descents are simply a U shape. Many will have tiny pockets and random bumps that will affect performance and the machine learning model needs to determine which way to head.  \n",
    "\n",
    "This function sums up the essence of the gradient descent algorithm and the missing piece that is solved in the next piece of code:  \n",
    "\n",
    "<img src=\"images/Gradient_Descent_Formula.webp\"\n",
    "     alt=\"linear ML model outcome\" />  \n",
    "\n",
    "\n",
    "Since we are looking for what's in red and we already know whats in blue, a learning rate, Something we determine ourselves through trial and error, is what's in green and now to calculate the derivatives will help determine our missing piece of whats in purple.  \n",
    "\n",
    "To calculate derivatives automatically, we can call requires_grad_() to perform that but any function with an (_) at the end will update the values  \n",
    "\n",
    "By calling requires_grad_() on the vector of coefficients, we state to the machine learning model that it is required to store the gradient values for each coefficient at each step. Almost like a recorded history of transactions, that way when we want to tweak the coefficients to get better performance, the model can see the long list of different changes we made and make better calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625], requires_grad=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs.requires_grad_() #pytorch method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By requiring that option, when calculating loss we gained the ability to attach the gradient function that stores the gradient values.  \n",
    "\n",
    "That gradient function is the key towards solving the purple section in the image above.  \n",
    "\n",
    "To get the result, the solution requires calculating the loss value to now use its value with the function we set to be required to calculate the direction  of fastest increase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5382, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = calc_loss(coeffs, t_indep, t_dep)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To call this function we call backward() that will calculate the coefficient gradient values into a variable called grad.\n",
    "\n",
    "This is necessary because we want our model to learn how to improve its ability to get the correct answer, part of that is going backwards and determining which coefficients we should change and by how much to improve its performance. This is called backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What do these numbers mean?\n",
    "\n",
    "The result below of coeffs.grad show what gradient values (aka which coefficients need changing and by how much) for each coefficient used to calculate loss above.  \n",
    "\n",
    "Positive vs negative values determine which direction the improvement needs to be made while the model needs to determine which gradient values are the largest such that they will have the greatest impact on improving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0106,  0.0129, -0.0041, -0.0484,  0.2099, -0.2132, -0.1212, -0.0247,  0.1425, -0.1886, -0.0191,  0.2043])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the gradient values we calculated through backpropagation and multiplying it by a learning rate we chose based on what we think is best will be subtracted from the current coefficients to create new coefficients to test.\n",
    "\n",
    "The formula from the image above is what this next piece of code performs and this image below describes how this process flows to train our model:  \n",
    "\n",
    "<img src=\"images/Simple_Learning_Algorithm.jpg\"\n",
    "     alt=\"linear ML model outcome\" />  \n",
    "\n",
    "\n",
    "If you now look at what the code block prints out, you will see that it has calculated the new loss value based on the new coefficients created.  \n",
    "\n",
    "Comparing the two: (old) 0.5382 > (new)0.5197 shows that there was improvement in lowering the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5197)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    coeffs.sub_(coeffs.grad * 0.1)\n",
    "    print(calc_loss(coeffs, t_indep, t_dep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the linear model\n",
    "\n",
    "Splitting your data for training and validation sets. We import a library that can split our data into these two sets via a random seed that we set.  \n",
    "\n",
    "For computers there is no real sense of randomness so us setting the seed will give it some sort of randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.transforms import RandomSplitter\n",
    "trn_split,val_split=RandomSplitter(seed=42)(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the split creates two variables that contain a list of indexes that are chosen for that specific set. The numbers you see printed below the code block are simply which numbers based on their row position were chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#178) [303,778,531,385,134,476,691,443,386,128...]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whats happening below:\n",
    "\n",
    "1. creating the list of actual row of independent values needed by calling the original dataset and only extracting whats required for each set.\n",
    "2. performing the same thing for the dependent variable in order to grade performance\n",
    "3. Grabbing the length of the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713, 178)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_indep,val_indep = t_indep[trn_split],t_indep[val_split] #1\n",
    "trn_dep,val_dep = t_dep[trn_split],t_dep[val_split] #2\n",
    "len(trn_indep),len(val_indep) #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking past code blocks and making them resusable.  \n",
    "\n",
    "The code function below makes the learning step reusable when training our linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_coeffs(coeffs, lr): \n",
    "    coeffs.sub_(coeffs.grad * lr)\n",
    "    coeffs.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function defines what an Epoch is in machine learning. \n",
    "\n",
    "An epoch is when all the training data is used at once and is defined as the total number of iterations of all the training data in one cycle for training the machine learning model  \n",
    "\n",
    "In our case, its form calculating loss, performing backpropagation, and updating the coefficients through gradient descent and our learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_epoch(coeffs, lr):\n",
    "    loss = calc_loss(coeffs, trn_indep, trn_dep)\n",
    "    loss.backward()\n",
    "    with torch.no_grad(): update_coeffs(coeffs, lr)\n",
    "    print(f\"{loss: .3f}\", end=\"; \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function makes creating the inital random variables reusable and this time attaches that the coefficients require the gradient values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coeffs(): return (torch.rand(n_coeff)-0.5).requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This bulky function ties all the previous functions together in a reusable step by step process to train your linear model based on what we created before.\n",
    "- We set the amount of epochs/times we want to run this process \n",
    "- We set the learning rate to increment each time we update the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs=30, lr=0.01):\n",
    "    torch.manual_seed(434)\n",
    "    coeffs = init_coeffs()\n",
    "    for i in range(epochs): one_epoch(coeffs, lr = lr)\n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the product of all the functions we made by running to train the model on 18 epochs with a learning rate of 0.02  \n",
    "\n",
    "Our output shows what the loss value of each epoch and how it steadily dropped to its final result of .218"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.595;  0.529;  0.477;  0.431;  0.385;  0.349;  0.325;  0.308;  0.299;  0.290;  0.314;  0.277;  0.303;  0.276;  0.290;  0.279;  0.287;  0.278; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(18, lr =0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Successfully Build and Trained a linear model\n",
    "\n",
    "The block below shows the loss for each coefficients. This gives insight how Age depending on how old, gave you less of a chance at surviving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': tensor(-0.0526),\n",
       " 'SibSp': tensor(0.0665),\n",
       " 'Parch': tensor(-0.2101),\n",
       " 'LogFare': tensor(-0.3478),\n",
       " 'Sex_male': tensor(-0.1469),\n",
       " 'Sex_female': tensor(0.7051),\n",
       " 'Pclass_1': tensor(0.5845),\n",
       " 'Pclass_2': tensor(0.4202),\n",
       " 'Pclass_3': tensor(0.3393),\n",
       " 'Embarked_C': tensor(0.0497),\n",
       " 'Embarked_Q': tensor(0.1165),\n",
       " 'Embarked_S': tensor(0.0920)}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_coeffs(): return dict(zip(indep_cols, coeffs.requires_grad_(False)))\n",
    "show_coeffs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring accuracy\n",
    "\n",
    "Mean absolute error as a performance measurement is great but not the only way to measure its performance.  \n",
    "\n",
    "Accuracy is another way to check for performance by first calculating the predictions like we did once before and storing it in preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = calc_preds(coeffs, val_indep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we take the predictions we made and pass it through a if statement.  \n",
    "\n",
    "We then create a threshold saying if the predicition is higher than 0.5, then it is True otherwise False. ex. --> (preds > 0.5)  \n",
    "\n",
    "We then compare the validation set named val_dep that has been passed through bool() which converts the matrix of 0 and 1 into true and false. Comparing it to what prediction was accurately considered true or false based on the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True, False, False, False,  True,  True, False])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = val_dep.bool()==(preds>0.5)\n",
    "results[:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we then convert the results matrix into a float so that pytorch can calculate it properly and take the mean we see that the accuracy of this model is .7921 or 79% accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7921)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is now created as a resusable function to test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7921)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def acc(coeffs): return (val_dep.bool()==(calc_preds(coeffs, val_indep)>0.5)).float().mean()\n",
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking back on the past predictions made, it shows how some predictions are represented with a negative value or greater than one which isn't all too great when trying to calculate the rate of the dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0815, 0.1722, 0.1088, 0.1132, 0.2017, 0.1789, 0.9077, 1.0518, 0.0396, 0.8759, 0.1413, 0.0442, 0.1159, 1.0233, 0.1497, 0.3151,\n",
       "        0.3020, 0.9821, 0.1559, 0.9894, 0.1468, 0.3079, 1.0240, 0.8905, 0.1550, 0.1216, 0.9699, 0.3039])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:28]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our solution for this problem would to import a mathmatical formula that could squish all possible numbers into a range of 0-1\n",
    "\n",
    "The sigmoid function is the key to making that happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sympy\n",
    "sympy.plot(\"1/(1+exp(-x))\", xlim=(-10,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redefine our function\n",
    "\n",
    "We take our prediction calculation function to now pass the result values through the sigmoid function above to make a more optimized result.  \n",
    "\n",
    "So that the bigger the number the closer to 1 while the smaller the number the closer its to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_preds(coeffs, indeps): return torch.sigmoid((indeps*coeffs).sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When retraining the model, the predictions are more in-line between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.550;  0.306;  0.209;  0.201;  0.200;  0.198;  0.198;  0.197;  0.197;  0.196;  0.196;  0.196;  0.196;  0.195;  0.195;  0.195;  0.195;  0.195;  0.195;  0.195;  0.195;  0.195;  0.194;  0.194;  0.194;  0.194;  0.194;  0.194;  0.194;  0.194; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(lr=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrating this sigmoid function will not affect the accuracy score at all. Since this dependent variable relies on a binary output, meaning whether survived is yes or no, the sigmoid function is almost necessary to ensure the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8258)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': tensor(-1.1117),\n",
       " 'SibSp': tensor(-1.2590),\n",
       " 'Parch': tensor(-0.9966),\n",
       " 'LogFare': tensor(-0.1989),\n",
       " 'Sex_male': tensor(-8.6799),\n",
       " 'Sex_female': tensor(7.9411),\n",
       " 'Pclass_1': tensor(3.2276),\n",
       " 'Pclass_2': tensor(2.4573),\n",
       " 'Pclass_3': tensor(-5.6379),\n",
       " 'Embarked_C': tensor(1.4539),\n",
       " 'Embarked_Q': tensor(1.9777),\n",
       " 'Embarked_S': tensor(-4.4705)}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_coeffs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving our processes: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using matrix product\n",
    "\n",
    "This new symbol @ works similarly to * for Matrix multiplication except that the * is actually element wise multiplication to include broadcasting since it multiplies numbers corresponding to their position in the matrix.  \n",
    "\n",
    "The @ symbol is the original matrix multiplication that is now replacing the previous iteration that was val_indep*coeffs.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 11.9600, -12.7427, -13.2647, -11.0806, -11.1246, -11.4215,   3.4503,   5.4547, -20.0446,   2.9996, -19.3028, -13.6098, -19.2470,\n",
       "          3.8778, -19.3250, -10.6539, -10.9318,   5.3093, -11.3401,  -2.6705, -19.1915, -10.8067,  11.6067,   4.6378, -19.1327, -12.9338,\n",
       "         -2.5843, -10.8901, -19.0969,   3.8782,   5.2615,  -3.6321, -19.1220, -19.2824,  11.8766,  -3.2676, -10.6893,  12.1535, -19.1921,\n",
       "         -2.7419, -11.0350, -19.1921, -11.6375,  12.0393, -19.1365,  -3.6857, -19.2788, -19.4193, -12.7397,  -2.5403,  -4.5446, -20.1558,\n",
       "        -19.9860, -19.2022, -11.1322, -11.2156, -12.7428, -19.5354, -19.1504, -19.2749,  -4.5224, -19.2485, -11.1440, -19.1499,   5.0540,\n",
       "        -10.5197, -11.1107, -19.4331, -13.3088,   5.2173, -19.2193,   3.0025, -11.2017, -19.1968, -10.3613, -19.0799, -19.1921, -10.7520,\n",
       "        -11.0412, -11.4346, -11.3054,  11.5061, -19.1776, -19.1891,   5.1553,  -5.7253,  -4.5558,   5.8612,  11.2032, -11.0968, -19.3043,\n",
       "        -19.1921,  12.0566, -13.3480,   3.1698,  -5.3528, -11.4374,   3.5310,   3.9060, -12.6694, -19.4315,   3.8782, -19.3027, -19.2749,\n",
       "        -10.6404, -11.3608, -19.2802,   4.9310,  -4.6474, -19.4152,   5.0321,  -2.8494, -10.3658,  12.3867, -19.1921,  11.4932,  -3.6037,\n",
       "        -12.7428, -19.4407,  11.5858, -19.9244,  -5.2955, -12.7428,  -3.3094, -13.2646, -10.4353,  -2.5840,  -2.5982, -19.0856, -11.5669,\n",
       "          6.3333, -19.3697,   5.1652,   5.3922,  11.9725, -19.1226, -11.5982, -19.2662,  -5.4873,   5.3430, -11.1941,  11.6032, -19.4798,\n",
       "        -12.8539,  -3.2435,   5.5261, -19.3887,   2.9909,   6.1918,   2.8783,  -2.8261,   3.5460,   5.5582, -13.3554, -13.0900, -20.8487,\n",
       "        -19.1921,  -2.6786, -11.2497, -19.2092,  12.1640,  -5.4361, -19.3762, -11.0655,  11.8007,   5.7637,   5.1476,   5.2601, -11.8117,\n",
       "        -10.7971,  -3.1067, -19.1397,   6.1008, -19.1968, -19.4695,   5.7294, -10.3663, -19.3270])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(val_indep*coeffs).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 11.9600, -12.7427, -13.2647, -11.0806, -11.1246, -11.4215,   3.4503,   5.4547, -20.0446,   2.9996, -19.3028, -13.6098, -19.2470,\n",
       "          3.8778, -19.3250, -10.6539, -10.9318,   5.3093, -11.3401,  -2.6705, -19.1915, -10.8067,  11.6067,   4.6378, -19.1327, -12.9338,\n",
       "         -2.5843, -10.8901, -19.0969,   3.8782,   5.2615,  -3.6321, -19.1220, -19.2824,  11.8766,  -3.2676, -10.6893,  12.1535, -19.1921,\n",
       "         -2.7419, -11.0350, -19.1921, -11.6375,  12.0393, -19.1365,  -3.6857, -19.2788, -19.4193, -12.7397,  -2.5403,  -4.5446, -20.1558,\n",
       "        -19.9860, -19.2022, -11.1322, -11.2156, -12.7428, -19.5354, -19.1504, -19.2749,  -4.5224, -19.2485, -11.1440, -19.1499,   5.0540,\n",
       "        -10.5197, -11.1107, -19.4331, -13.3088,   5.2173, -19.2193,   3.0025, -11.2017, -19.1968, -10.3613, -19.0799, -19.1921, -10.7520,\n",
       "        -11.0412, -11.4346, -11.3054,  11.5061, -19.1776, -19.1891,   5.1553,  -5.7253,  -4.5558,   5.8612,  11.2032, -11.0968, -19.3043,\n",
       "        -19.1921,  12.0566, -13.3480,   3.1698,  -5.3528, -11.4374,   3.5310,   3.9060, -12.6694, -19.4315,   3.8782, -19.3027, -19.2749,\n",
       "        -10.6404, -11.3608, -19.2802,   4.9310,  -4.6474, -19.4152,   5.0321,  -2.8494, -10.3658,  12.3867, -19.1921,  11.4932,  -3.6037,\n",
       "        -12.7428, -19.4407,  11.5858, -19.9244,  -5.2955, -12.7428,  -3.3094, -13.2646, -10.4353,  -2.5840,  -2.5982, -19.0856, -11.5669,\n",
       "          6.3333, -19.3697,   5.1652,   5.3922,  11.9725, -19.1226, -11.5982, -19.2662,  -5.4873,   5.3430, -11.1941,  11.6032, -19.4798,\n",
       "        -12.8539,  -3.2435,   5.5261, -19.3887,   2.9909,   6.1918,   2.8783,  -2.8261,   3.5460,   5.5582, -13.3554, -13.0900, -20.8487,\n",
       "        -19.1921,  -2.6786, -11.2497, -19.2092,  12.1640,  -5.4361, -19.3762, -11.0655,  11.8007,   5.7637,   5.1476,   5.2601, -11.8117,\n",
       "        -10.7971,  -3.1067, -19.1397,   6.1008, -19.1968, -19.4695,   5.7294, -10.3663, -19.3270])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_indep@coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplifying function we had before to implement sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_preds(coeffs, indeps): return torch.sigmoid(indeps@coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating this one slightly to add not only an n_coeff length vector of coefficients, but now it is a matrix with its dimesnsions as n_coeff x 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coeffs(): return (torch.rand(n_coeff, 1)*0.1).requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trn_dep and val_dep are technically vectors and not recognized as matrices. Because of this, performing matrix multiplication between a vector and a matrix will not produce a matrix.  \n",
    "\n",
    "Reformatting these vectors to matrices to have defined 1 \"column\" is really the same how a vector is just one column with a given amount of rows.  \n",
    "\n",
    "This format is only possible through the code syntax below as the key word None after the comma specifies that another row is needed but nothing will fill its space. This effectively makes a matrix equivalent to a vector. (Vectors are still technically matrices but computers are weird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dep = trn_dep[:, None]\n",
    "val_dep = val_dep[:, None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([713, 1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_dep.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-run our training model to test if our results stayed the same with this new change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.517;  0.346;  0.301;  0.276;  0.261;  0.251;  0.245;  0.240;  0.236;  0.233;  0.231;  0.229;  0.227;  0.226;  0.225;  0.224;  0.223;  0.222;  0.221;  0.220;  0.219;  0.219;  0.218;  0.218;  0.217;  0.216;  0.216;  0.215;  0.215;  0.215; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(lr=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noticed a slight increase in accuracy from the last run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8371)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking note that since our vector change, the output of the coefficients has updated to also a matrix of 12 x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4400],\n",
       "        [-0.4568],\n",
       "        [-0.2386],\n",
       "        [ 0.1695],\n",
       "        [-3.7836],\n",
       "        [ 3.4341],\n",
       "        [ 1.0979],\n",
       "        [ 0.8266],\n",
       "        [-2.1455],\n",
       "        [ 0.3479],\n",
       "        [ 0.5392],\n",
       "        [-1.2166]], requires_grad=True)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Neural Network\n",
    "\n",
    "<img src=\"images/neural_network-1024x707.webp\"\n",
    "     alt=\"linear ML model outcome\" />  \n",
    "\n",
    "The image above is a visual representation of how a neural network works.  \n",
    "\n",
    "The input layer is just they way the computer hands the data to the first \"hidden\" layer.  \n",
    "A layer is just those column/s of coefficients created randomly that will be tested, calculated for loss, updated and recalculated till deemed fit.  \n",
    "What makes it \"hidden\" comes from not having to directly interact with it, but allowed to run behind the scenes.  \n",
    "The image contains two hidden layers but anyone can increase the amount to what they require, that just means to create more rows of coefficients.  \n",
    "\n",
    "The more complex your data results in the more coefficients in your rows, the more factors in play for your dependent variable the more layers are needed. Of course increasing one aspect of the neural network will cause an increase in all aspects.\n",
    "\n",
    "\n",
    "  \n",
    "The function states that 20 columns of coefficients is specified for the hidden layers are going to be created(In this example its just one), the values for those 20 columns of coefficients are normalized by keeping their range between -0.5 to 0.5. To make sure the values also dont jump in value the next matrix multiplication, dividing by n_hidden keeps them low enough.\n",
    "  \n",
    "Layer 2 variable is there to create the coefficients needed to multiply against the matrix just created. This process is similar to this -> torch.rand(n_coeff, 1)*0.1).requires_grad_() where torch.rand(n_coeff,1) is now what layer 1 variable is doing while the *0.1 now needs to be handled by layer 2.  \n",
    "\n",
    "With all neural networks is customary to create a random constant term to ensure some sort of result is outputted in case of error so the const variable is created as a scalar vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coeffs(n_hidden=20):\n",
    "    layer1 = (torch.rand(n_coeff, n_hidden)-0.5)/n_hidden # based on image, process is input layer to hidden layers\n",
    "    layer2 = torch.rand(n_hidden, 1)-0.3 # based on the image, process leads from the hidden layers to one output\n",
    "    const = torch.rand(1)[0]\n",
    "    return layer1.requires_grad_(),layer2.requires_grad_(),const.requires_grad_() # returns a tuple - a list of values that are finite and unable to be changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If above did not make much sense, the update to the next method explains better on how the process now works.  \n",
    "\n",
    "This is what calc_preds(coeffs, indeps) did previously:  \n",
    "```\n",
    "def calc_preds(coeffs, indeps): return torch.sigmoid(indeps@coeffs)\n",
    "\n",
    "```  \n",
    "\n",
    "The process for matrix multiplication is slightly more complicated than just mutliplying a single column of coefficients to the independent variable matrix.  \n",
    "Now the process within calc_preds goes in this order:\n",
    "- separate the output of coeffs into three variables of l2, l2, const. (these correspond to the order that is outputted by init_coeffs above)\n",
    "- the result variable is created and now the first matrix multiplication begins with the independent variable matrix and layer 1 and its hidden layers (also relu() replaces any negatives with zeros since its the activiation function)\n",
    "- Now perform the second matrix mutliply for the final layer of the neural network to output a single value and add it with the const\n",
    "- apply sigmoid to balance it and return its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def calc_preds(coeffs, indeps):\n",
    "    l1,l2,const = coeffs\n",
    "    res = F.relu(indeps@l1)\n",
    "    res = res@l2 + const\n",
    "    return torch.sigmoid(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above executes the bulk of what an epoch would perform and now the newly updated update_coeffs function has to account for multiple columns considered as layers to be updated based on what their gradient values were calculated as, then all are then multiplied by a specified learning rate.  \n",
    "\n",
    "consider this process as a whole rather than individual parts because its essentially the same as how it was performed previously with only one column of coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_coeffs(coeffs, lr):\n",
    "    for layer in coeffs: \n",
    "        layer.sub_(layer.grad * lr)\n",
    "        layer.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_model needed no update to keep up with its counterparts since train_model only provides the order of operations for other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.560;  0.546;  0.532;  0.509;  0.480;  0.442;  0.390;  0.330;  0.285;  0.260;  0.245;  0.236;  0.230;  0.226;  0.223;  0.221;  0.219;  0.217;  0.215;  0.214;  0.212;  0.211;  0.210;  0.209;  0.208;  0.207;  0.206;  0.206;  0.205;  0.204;  0.204;  0.203;  0.203;  0.202;  0.202;  0.201;  0.201;  0.201;  0.200;  0.200;  0.200;  0.199;  0.199;  0.199;  0.199;  0.198;  0.198;  0.198;  0.198;  0.198; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(epochs= 50,lr=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the training it appears that despite upgrading from a linear model to neural network that the accuracy has not improved. This may happen from tim to time and for a number of factors. In this case the dataset is very small and simple so the neural network cannot be fully utilized. On top of that, it affects how small our validation set to calculate accuracy so that also comes into play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8258)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "We are increasing the hidden layers from just one, to n number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([tensor([[     0.0597,     -0.1089,     -0.1872,      0.1503,      0.0349,      0.0843,      0.0638,     -0.1305,      0.0323,      0.1657],\n",
       "          [    -0.1835,      0.0139,     -0.1497,      0.0631,     -0.1032,      0.1773,      0.0145,     -0.1507,      0.0144,     -0.0591],\n",
       "          [     0.0761,     -0.1209,      0.0845,     -0.0227,      0.1019,      0.0859,     -0.1904,     -0.1003,      0.1576,     -0.1862],\n",
       "          [     0.0196,      0.0991,      0.0810,      0.0736,     -0.0344,     -0.1892,      0.0950,     -0.1968,     -0.1044,      0.1909],\n",
       "          [     0.0753,      0.0645,      0.0397,     -0.0046,      0.1985,     -0.1713,     -0.1519,      0.1284,     -0.0721,      0.0447],\n",
       "          [    -0.1499,      0.1185,     -0.1389,     -0.1115,     -0.1626,      0.0146,      0.0188,     -0.1037,      0.1803,     -0.1398],\n",
       "          [     0.1310,     -0.0644,      0.0780,     -0.1676,     -0.1036,     -0.1120,     -0.1389,      0.0547,     -0.1469,     -0.1534],\n",
       "          [    -0.0186,      0.1257,      0.1910,     -0.0328,     -0.1038,     -0.1527,      0.1772,     -0.1342,     -0.0898,      0.0461],\n",
       "          [    -0.1970,      0.0890,     -0.1757,     -0.1046,      0.0056,      0.1944,     -0.1124,      0.0714,     -0.1206,      0.0933],\n",
       "          [    -0.0855,      0.1765,      0.0851,      0.0001,     -0.1860,      0.0577,      0.1914,     -0.1655,     -0.0193,      0.1295],\n",
       "          [    -0.0444,     -0.1326,      0.0630,     -0.1239,     -0.0815,      0.0856,      0.1507,      0.1745,     -0.0750,      0.0618],\n",
       "          [    -0.0534,      0.1719,      0.0882,     -0.0588,     -0.1874,     -0.0470,     -0.1594,      0.0834,      0.0360,      0.1769]],\n",
       "         requires_grad=True),\n",
       "  tensor([[ 0.1724, -0.0702,  0.0243,  0.0471, -0.1346, -0.1407,  0.1660,  0.1016,  0.1028,  0.1671],\n",
       "          [-0.1660, -0.0066, -0.1511,  0.0499,  0.0201,  0.0989, -0.0268, -0.1190,  0.1915,  0.0381],\n",
       "          [ 0.0775, -0.1598,  0.1677, -0.0895, -0.1113, -0.1861, -0.0209, -0.1794,  0.1537,  0.1242],\n",
       "          [ 0.0836, -0.1752,  0.0202,  0.1611, -0.1725, -0.0743, -0.0110,  0.1002, -0.0419, -0.1257],\n",
       "          [ 0.1916,  0.0252, -0.0143, -0.0429,  0.1189, -0.1689, -0.0217, -0.0327, -0.0476, -0.0554],\n",
       "          [-0.0782,  0.0142,  0.1227, -0.1895,  0.0983,  0.1253, -0.1096,  0.1520, -0.1533, -0.0171],\n",
       "          [ 0.1232, -0.0769,  0.1147,  0.0434, -0.1001, -0.0856,  0.0040, -0.1797, -0.1234,  0.0482],\n",
       "          [ 0.0928, -0.1340,  0.0250, -0.0523, -0.1330, -0.1020, -0.0126,  0.0932,  0.0729,  0.0328],\n",
       "          [-0.0443, -0.0949, -0.1187,  0.1820,  0.1322, -0.0202, -0.1303, -0.0433, -0.0900,  0.0037],\n",
       "          [ 0.0667,  0.0303, -0.1822, -0.1658,  0.1213, -0.1328,  0.0278,  0.0908,  0.1326,  0.0012]], requires_grad=True),\n",
       "  tensor([[-0.0583],\n",
       "          [-0.8540],\n",
       "          [-1.9057],\n",
       "          [-1.7072],\n",
       "          [-0.4921],\n",
       "          [-0.3238],\n",
       "          [-1.8022],\n",
       "          [ 1.4369],\n",
       "          [-0.3649],\n",
       "          [-0.0357]], requires_grad=True)],\n",
       " [tensor(-0.0441, requires_grad=True),\n",
       "  tensor(-0.0187, requires_grad=True),\n",
       "  tensor(0.0286, requires_grad=True)])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_coeffs():\n",
    "    hiddens = [10, 10] # <- set this to the size of each hidden layer that you would want\n",
    "    sizes = [n_coeff] + hiddens + [1] # sizes now equals the number of required coefficients + the number of hidden layers set + 1 creating the new matrix\n",
    "    n = len(sizes) # Gets the new length based on new hidden layer requirements\n",
    "    print(n)\n",
    "    layers = [(torch.rand(sizes[i], sizes[i+1])-0.5)/sizes[i+1]*4 for i in range(n-1)] # calculate based on the range between 0 to n-1, the random number generated from (index at i and i + 1) - 0.3 / index i +1*4\n",
    "    consts = [(torch.rand(1)[0]-0.5)*0.1 for i in range(n-1)]\n",
    "    for l in layers+consts: l.requires_grad_()\n",
    "    return layers,consts\n",
    "\n",
    "init_coeffs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def calc_preds(coeffs, indeps):\n",
    "    layers, consts = coeffs\n",
    "    n = len(layers)\n",
    "    res = indeps\n",
    "    for i, l in enumerate(layers): # loops all the layers of the matrix\n",
    "        res = res@l + consts[i]  # performs matrix multiplication then adds the constant\n",
    "        if i!= n-1: res = F.relu(res) # perform relu as long as its not the last layer\n",
    "    return torch.sigmoid(res) # if last layer then perform the final sigmoid function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training the coefficients need to be updated based on their work\n",
    "def update_coeffs(coeffs, lr):\n",
    "    layers,consts = coeffs\n",
    "    for layer in layers+consts: layer.sub_(layer.grad * lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      " 0.514;  0.496;  0.486;  0.471;  0.453;  0.434;  0.416;  0.403;  0.393;  0.387;  0.384;  0.381;  0.380;  0.380;  0.379;  0.379;  0.379;  0.379;  0.379;  0.379;  0.379;  0.379;  0.379;  0.379;  0.379;  0.379;  0.379;  0.379;  0.379;  0.379; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(lr=1.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5955)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopped at 1:09:48"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
