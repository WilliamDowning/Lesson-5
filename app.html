<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Lesson 5: Understanding of Linear Models, Training Models, Neural Networks and how they work</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="app_files/libs/clipboard/clipboard.min.js"></script>
<script src="app_files/libs/quarto-html/quarto.js"></script>
<script src="app_files/libs/quarto-html/popper.min.js"></script>
<script src="app_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="app_files/libs/quarto-html/anchor.min.js"></script>
<link href="app_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="app_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="app_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="app_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="app_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Lesson 5: Understanding of Linear Models, Training Models, Neural Networks and how they work</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>The purpose of this notebook is to understand the innerworkings of the most basic machine learning frameworks. On top of that, it explores why each step must happen before another.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>iskaggle <span class="op">=</span> os.environ.get(<span class="st">'KAGGLE_KERNEL_RUN_TYPE'</span>, <span class="st">''</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> iskaggle: path <span class="op">-</span> Path(<span class="st">'../input/titanic'</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    path <span class="op">=</span> Path(<span class="st">'titanic'</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> path.exists():</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>        <span class="im">import</span> zipfile,kaggle</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>        kaggle.api.competition_download_cli(<span class="bu">str</span>(path))</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>        zipfile.ZipFile(<span class="ss">f'</span><span class="sc">{</span>path<span class="sc">}</span><span class="ss">.zip'</span>).extractall(path)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch, numpy <span class="im">as</span> np, pandas <span class="im">as</span> pd, matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>np.set_printoptions(linewidth<span class="op">=</span><span class="dv">140</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>torch.set_printoptions(linewidth<span class="op">=</span><span class="dv">140</span>, sci_mode<span class="op">=</span><span class="va">False</span>, edgeitems<span class="op">=</span><span class="dv">7</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">'display.width'</span>, <span class="dv">140</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="cleaning-up-our-dataset" class="level2">
<h2 class="anchored" data-anchor-id="cleaning-up-our-dataset">Cleaning Up Our Dataset</h2>
<p>This dataset is grabbed from this site: https://www.kaggle.com/competitions/titanic</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> Path(<span class="st">'titanic'</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(path<span class="op">/</span><span class="st">'train.csv'</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">PassengerId</th>
<th data-quarto-table-cell-role="th">Survived</th>
<th data-quarto-table-cell-role="th">Pclass</th>
<th data-quarto-table-cell-role="th">Name</th>
<th data-quarto-table-cell-role="th">Sex</th>
<th data-quarto-table-cell-role="th">Age</th>
<th data-quarto-table-cell-role="th">SibSp</th>
<th data-quarto-table-cell-role="th">Parch</th>
<th data-quarto-table-cell-role="th">Ticket</th>
<th data-quarto-table-cell-role="th">Fare</th>
<th data-quarto-table-cell-role="th">Cabin</th>
<th data-quarto-table-cell-role="th">Embarked</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>0</td>
<td>3</td>
<td>Braund, Mr. Owen Harris</td>
<td>male</td>
<td>22.0</td>
<td>1</td>
<td>0</td>
<td>A/5 21171</td>
<td>7.2500</td>
<td>NaN</td>
<td>S</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2</td>
<td>1</td>
<td>1</td>
<td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
<td>female</td>
<td>38.0</td>
<td>1</td>
<td>0</td>
<td>PC 17599</td>
<td>71.2833</td>
<td>C85</td>
<td>C</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>3</td>
<td>1</td>
<td>3</td>
<td>Heikkinen, Miss. Laina</td>
<td>female</td>
<td>26.0</td>
<td>0</td>
<td>0</td>
<td>STON/O2. 3101282</td>
<td>7.9250</td>
<td>NaN</td>
<td>S</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4</td>
<td>1</td>
<td>1</td>
<td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
<td>female</td>
<td>35.0</td>
<td>1</td>
<td>0</td>
<td>113803</td>
<td>53.1000</td>
<td>C123</td>
<td>S</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>5</td>
<td>0</td>
<td>3</td>
<td>Allen, Mr. William Henry</td>
<td>male</td>
<td>35.0</td>
<td>0</td>
<td>0</td>
<td>373450</td>
<td>8.0500</td>
<td>NaN</td>
<td>S</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">886</td>
<td>887</td>
<td>0</td>
<td>2</td>
<td>Montvila, Rev. Juozas</td>
<td>male</td>
<td>27.0</td>
<td>0</td>
<td>0</td>
<td>211536</td>
<td>13.0000</td>
<td>NaN</td>
<td>S</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">887</td>
<td>888</td>
<td>1</td>
<td>1</td>
<td>Graham, Miss. Margaret Edith</td>
<td>female</td>
<td>19.0</td>
<td>0</td>
<td>0</td>
<td>112053</td>
<td>30.0000</td>
<td>B42</td>
<td>S</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">888</td>
<td>889</td>
<td>0</td>
<td>3</td>
<td>Johnston, Miss. Catherine Helen "Carrie"</td>
<td>female</td>
<td>NaN</td>
<td>1</td>
<td>2</td>
<td>W./C. 6607</td>
<td>23.4500</td>
<td>NaN</td>
<td>S</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">889</td>
<td>890</td>
<td>1</td>
<td>1</td>
<td>Behr, Mr. Karl Howell</td>
<td>male</td>
<td>26.0</td>
<td>0</td>
<td>0</td>
<td>111369</td>
<td>30.0000</td>
<td>C148</td>
<td>C</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">890</td>
<td>891</td>
<td>0</td>
<td>3</td>
<td>Dooley, Mr. Patrick</td>
<td>male</td>
<td>32.0</td>
<td>0</td>
<td>0</td>
<td>370376</td>
<td>7.7500</td>
<td>NaN</td>
<td>Q</td>
</tr>
</tbody>
</table>

<p>891 rows × 12 columns</p>
</div>
</div>
</div>
<p>df is our dataframe which is a kind of table formatted specifically by Pandas<br>
The code below is looking for the number of non-alphanumerical (null) values. It will then detail a summation amount per each column.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>df.isna().<span class="bu">sum</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>PassengerId      0
Survived         0
Pclass           0
Name             0
Sex              0
Age            177
SibSp            0
Parch            0
Ticket           0
Fare             0
Cabin          687
Embarked         2
dtype: int64</code></pre>
</div>
</div>
<p>Performing a mode calculation of the most common values in the table. Then to make sure you grab the most common will always be stored as the first row going in descending order. This is why to call mode() followed by iloc[] which takes the starting index between [].</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>modes <span class="op">=</span> df.mode().iloc[<span class="dv">0</span>]</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>modes</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>PassengerId                      1
Survived                       0.0
Pclass                         3.0
Name           Abbing, Mr. Anthony
Sex                           male
Age                           24.0
SibSp                          0.0
Parch                          0.0
Ticket                        1601
Fare                          8.05
Cabin                      B96 B98
Embarked                         S
Name: 0, dtype: object</code></pre>
</div>
</div>
<p>Taking all the null spaces that create holes in our table and fill them with the most common value in that column. This is one of many techniques of cleaning data for machine learning. The author finds this method the best given how small the dataset is, but recognizes how doing this can affect cause highly inaccurate predictions depending on how volatile changing all null values to common ones.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>df.fillna(modes, inplace <span class="op">=</span> <span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>df.isna().<span class="bu">sum</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>PassengerId    0
Survived       0
Pclass         0
Name           0
Sex            0
Age            0
SibSp          0
Parch          0
Ticket         0
Fare           0
Cabin          0
Embarked       0
dtype: int64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>df.describe(include<span class="op">=</span>(np.number))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">PassengerId</th>
<th data-quarto-table-cell-role="th">Survived</th>
<th data-quarto-table-cell-role="th">Pclass</th>
<th data-quarto-table-cell-role="th">Age</th>
<th data-quarto-table-cell-role="th">SibSp</th>
<th data-quarto-table-cell-role="th">Parch</th>
<th data-quarto-table-cell-role="th">Fare</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">count</td>
<td>891.000000</td>
<td>891.000000</td>
<td>891.000000</td>
<td>891.000000</td>
<td>891.000000</td>
<td>891.000000</td>
<td>891.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">mean</td>
<td>446.000000</td>
<td>0.383838</td>
<td>2.308642</td>
<td>28.566970</td>
<td>0.523008</td>
<td>0.381594</td>
<td>32.204208</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">std</td>
<td>257.353842</td>
<td>0.486592</td>
<td>0.836071</td>
<td>13.199572</td>
<td>1.102743</td>
<td>0.806057</td>
<td>49.693429</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">min</td>
<td>1.000000</td>
<td>0.000000</td>
<td>1.000000</td>
<td>0.420000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">25%</td>
<td>223.500000</td>
<td>0.000000</td>
<td>2.000000</td>
<td>22.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>7.910400</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">50%</td>
<td>446.000000</td>
<td>0.000000</td>
<td>3.000000</td>
<td>24.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>14.454200</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">75%</td>
<td>668.500000</td>
<td>1.000000</td>
<td>3.000000</td>
<td>35.000000</td>
<td>1.000000</td>
<td>0.000000</td>
<td>31.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">max</td>
<td>891.000000</td>
<td>1.000000</td>
<td>3.000000</td>
<td>80.000000</td>
<td>8.000000</td>
<td>6.000000</td>
<td>512.329200</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Displaying Fare as a histogram shows how skewed or underrespresented the value will be.</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'Fare'</span>].hist()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>&lt;Axes: &gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="app_files/figure-html/cell-10-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>It can be said that this value could benefit from modification to help provide a better spread. This could give massive improvements if the value has potential to provide a trend in the data.</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'LogFare'</span>] <span class="op">=</span> np.log(df[<span class="st">'Fare'</span>] <span class="op">+</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Sending the Fare through a Log function results in this new histogram that better represents the column we want to predict with</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'LogFare'</span>].hist()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>&lt;Axes: &gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="app_files/figure-html/cell-12-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>Checking the purpose of Pclass column (They seem to be categories)</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>pclasses <span class="op">=</span> <span class="bu">sorted</span>(df.Pclass.unique())</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>pclasses</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>[1, 2, 3]</code></pre>
</div>
</div>
<p>Describe shows all non-numeric variables, their count, how many unique ones there are and the top and frequency of the values.</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>df.describe(include<span class="op">=</span>[<span class="bu">object</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Name</th>
<th data-quarto-table-cell-role="th">Sex</th>
<th data-quarto-table-cell-role="th">Ticket</th>
<th data-quarto-table-cell-role="th">Cabin</th>
<th data-quarto-table-cell-role="th">Embarked</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">count</td>
<td>891</td>
<td>891</td>
<td>891</td>
<td>891</td>
<td>891</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">unique</td>
<td>891</td>
<td>2</td>
<td>681</td>
<td>147</td>
<td>3</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">top</td>
<td>Dooley, Mr. Patrick</td>
<td>male</td>
<td>1601</td>
<td>B96 B98</td>
<td>S</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">freq</td>
<td>1</td>
<td>577</td>
<td>7</td>
<td>691</td>
<td>646</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>We need to be able to multiply these non-numeric columns by coefficients so we need to make dummy variables of true (1) or false (0) boolean columns</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.get_dummies(df, columns<span class="op">=</span>[<span class="st">"Sex"</span>, <span class="st">"Pclass"</span>, <span class="st">"Embarked"</span>], dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>df.columns</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>Index(['PassengerId', 'Survived', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'LogFare', 'Sex_female', 'Sex_male',
       'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],
      dtype='object')</code></pre>
</div>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>added_cols <span class="op">=</span> [<span class="st">'Sex_male'</span>, <span class="st">'Sex_female'</span>, <span class="st">'Pclass_1'</span>, <span class="st">'Pclass_2'</span>, <span class="st">'Pclass_3'</span>, <span class="st">'Embarked_C'</span>, <span class="st">'Embarked_Q'</span>, <span class="st">'Embarked_S'</span>]</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>df[added_cols].head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Sex_male</th>
<th data-quarto-table-cell-role="th">Sex_female</th>
<th data-quarto-table-cell-role="th">Pclass_1</th>
<th data-quarto-table-cell-role="th">Pclass_2</th>
<th data-quarto-table-cell-role="th">Pclass_3</th>
<th data-quarto-table-cell-role="th">Embarked_C</th>
<th data-quarto-table-cell-role="th">Embarked_Q</th>
<th data-quarto-table-cell-role="th">Embarked_S</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.0</td>
<td>1.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0.0</td>
<td>1.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Creates a tensor matrix of the dependent variable, whether the entry has survived or not</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> tensor</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>t_dep <span class="op">=</span> tensor(df.Survived)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Creates another tensor matrix of the independent variables that we will test with to predict if the entry survived or not. It includes the rows we had to clean such as LogFare(formally Fare), ‘Sex_male’ and ‘Sex_female’(formally Sex), ‘Pclass_1’, ‘Pclass_2’ and ‘Pclass_3’(formally known as Pclass) and finally ‘Embarked_C’, ‘Embarked_Q’ and ‘Embarked_S’(formally Embarked).</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>indep_cols <span class="op">=</span> [<span class="st">'Age'</span>,<span class="st">'SibSp'</span>,<span class="st">'Parch'</span>,<span class="st">'LogFare'</span>] <span class="op">+</span> added_cols</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>t_indep <span class="op">=</span> tensor(df[indep_cols].values, dtype<span class="op">=</span>torch.<span class="bu">float</span>)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>t_indep</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>tensor([[22.0000,  1.0000,  0.0000,  2.1102,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],
        [38.0000,  1.0000,  0.0000,  4.2806,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],
        [26.0000,  0.0000,  0.0000,  2.1889,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],
        [35.0000,  1.0000,  0.0000,  3.9908,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],
        [35.0000,  0.0000,  0.0000,  2.2028,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],
        [24.0000,  0.0000,  0.0000,  2.2469,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000],
        [54.0000,  0.0000,  0.0000,  3.9677,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],
        ...,
        [25.0000,  0.0000,  0.0000,  2.0857,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],
        [39.0000,  0.0000,  5.0000,  3.4054,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000],
        [27.0000,  0.0000,  0.0000,  2.6391,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000],
        [19.0000,  0.0000,  0.0000,  3.4340,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],
        [24.0000,  1.0000,  2.0000,  3.1966,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],
        [26.0000,  0.0000,  0.0000,  3.4340,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],
        [32.0000,  0.0000,  0.0000,  2.1691,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000]])</code></pre>
</div>
</div>
<p>Shows you how many rows and columns</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>t_indep.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>torch.Size([891, 12])</code></pre>
</div>
</div>
<p>Tells you the number of (rank) dimensions the tensor has, a vector is rank 1, a matrix is rank 2</p>
<p><img src="images/Tensor.png" alt="linear ML model outcome"></p>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(t_indep.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>2</code></pre>
</div>
</div>
</section>
<section id="setting-up-a-linear-model" class="level1">
<h1>Setting up a linear model</h1>
<p>We need to multiply our rows of data by coefficients that are randomized and made for each column:</p>
<p><img src="images/Example-of-a-linear-ML-model-The-outcome-y-is-predicted-by-the-multiplication-of-feature.png" alt="linear ML model outcome"></p>
<p>The vector can be understood as a series of weights visually like such:</p>
<p><img src="images/Weights.png" alt="linear ML model outcome"></p>
<p>1 Set the seed for the tensor to simulate creating some “random” number generation.<br>
2 Grabbing the number of coefficients we need to multiply against our matrix.<br>
3 Generate n_coeff amount of random coefficients between 0 and 1. We subtract 0.5 to center the values so max = 0.5 and min = -0.5.</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">442</span>) <span class="co">#1</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>n_coeff <span class="op">=</span> t_indep.shape[<span class="dv">1</span>] <span class="co">#2</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>coeffs <span class="op">=</span> torch.rand(n_coeff) <span class="op">-</span> <span class="fl">0.5</span> <span class="co">#3</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>coeffs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625])</code></pre>
</div>
</div>
<p>We then multiply our matrix to our vector via element-wise multiplication through broadcasting and the use of (*) symbol:</p>
<p><img src="images/Numpy-Broadcasting.png" alt="linear ML model outcome"></p>
<p>Seeing that our Matrix was 861 rows and 12 columns. Our Vector matches to have 12 coefficients that will broadcast that:</p>
<ul>
<li><p>For every coefficient in the vector, each row of the matrix will be mutiplied by that same coefficient based on the index of that column.</p></li>
<li><p>Our vector becomes a matrix with a repeating values for over 861 rows</p></li>
</ul>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>t_indep<span class="op">*</span>coeffs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>tensor([[-10.1838,   0.1386,   0.0000,  -0.4772,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],
        [-17.5902,   0.1386,   0.0000,  -0.9681,  -0.0000,  -0.3147,   0.4876,   0.0000,   0.0000,  -0.4392,   0.0000,   0.0000],
        [-12.0354,   0.0000,   0.0000,  -0.4950,  -0.0000,  -0.3147,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],
        [-16.2015,   0.1386,   0.0000,  -0.9025,  -0.0000,  -0.3147,   0.4876,   0.0000,   0.0000,  -0.0000,   0.0000,   0.3625],
        [-16.2015,   0.0000,   0.0000,  -0.4982,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],
        [-11.1096,   0.0000,   0.0000,  -0.5081,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.2103,   0.0000],
        [-24.9966,   0.0000,   0.0000,  -0.8973,  -0.2632,  -0.0000,   0.4876,   0.0000,   0.0000,  -0.0000,   0.0000,   0.3625],
        ...,
        [-11.5725,   0.0000,   0.0000,  -0.4717,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],
        [-18.0531,   0.0000,   1.2045,  -0.7701,  -0.0000,  -0.3147,   0.0000,   0.0000,   0.2799,  -0.0000,   0.2103,   0.0000],
        [-12.4983,   0.0000,   0.0000,  -0.5968,  -0.2632,  -0.0000,   0.0000,   0.3136,   0.0000,  -0.0000,   0.0000,   0.3625],
        [ -8.7951,   0.0000,   0.0000,  -0.7766,  -0.0000,  -0.3147,   0.4876,   0.0000,   0.0000,  -0.0000,   0.0000,   0.3625],
        [-11.1096,   0.1386,   0.4818,  -0.7229,  -0.0000,  -0.3147,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],
        [-12.0354,   0.0000,   0.0000,  -0.7766,  -0.2632,  -0.0000,   0.4876,   0.0000,   0.0000,  -0.4392,   0.0000,   0.0000],
        [-14.8128,   0.0000,   0.0000,  -0.4905,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.2103,   0.0000]])</code></pre>
</div>
</div>
<p>Since the first column above has a big outputs compared to its other columns, this means when it will be multiplied by its coefficient that it will be significantly impacted differently than the other columns. To fix that we are going to normalize the values by dividing by the maximum value.</p>
<p>We pass dim = 0 within max to specify that we want the maximum found within the rows and not the columns which would be dim = 1</p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>vals,indices <span class="op">=</span> t_indep.<span class="bu">max</span>(dim <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>t_indep <span class="op">=</span> t_indep <span class="op">/</span> vals</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>vals</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>tensor([80.0000,  8.0000,  6.0000,  6.2409,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000])</code></pre>
</div>
</div>
<p>We now see that the values are evened out across all columns</p>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>t_indep<span class="op">*</span>coeffs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>tensor([[-0.1273,  0.0173,  0.0000, -0.0765, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],
        [-0.2199,  0.0173,  0.0000, -0.1551, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.4392,  0.0000,  0.0000],
        [-0.1504,  0.0000,  0.0000, -0.0793, -0.0000, -0.3147,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],
        [-0.2025,  0.0173,  0.0000, -0.1446, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.0000,  0.0000,  0.3625],
        [-0.2025,  0.0000,  0.0000, -0.0798, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],
        [-0.1389,  0.0000,  0.0000, -0.0814, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.2103,  0.0000],
        [-0.3125,  0.0000,  0.0000, -0.1438, -0.2632, -0.0000,  0.4876,  0.0000,  0.0000, -0.0000,  0.0000,  0.3625],
        ...,
        [-0.1447,  0.0000,  0.0000, -0.0756, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],
        [-0.2257,  0.0000,  0.2008, -0.1234, -0.0000, -0.3147,  0.0000,  0.0000,  0.2799, -0.0000,  0.2103,  0.0000],
        [-0.1562,  0.0000,  0.0000, -0.0956, -0.2632, -0.0000,  0.0000,  0.3136,  0.0000, -0.0000,  0.0000,  0.3625],
        [-0.1099,  0.0000,  0.0000, -0.1244, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.0000,  0.0000,  0.3625],
        [-0.1389,  0.0173,  0.0803, -0.1158, -0.0000, -0.3147,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],
        [-0.1504,  0.0000,  0.0000, -0.1244, -0.2632, -0.0000,  0.4876,  0.0000,  0.0000, -0.4392,  0.0000,  0.0000],
        [-0.1852,  0.0000,  0.0000, -0.0786, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.2103,  0.0000]])</code></pre>
</div>
</div>
<p>axis = 1 specfies that we want to add up our multipied matrix by the columns rather than the rows.</p>
<p>This is suppose to help determine our predictions as each coefficient in each row is an independent weight that will determine what the dependent variable will result in. For this case its whether or not they survived the titanic</p>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> (t_indep<span class="op">*</span>coeffs).<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The first ten rows of the prediction values</p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>preds[:<span class="dv">10</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>tensor([ 0.1927, -0.6239,  0.0979,  0.2056,  0.0968,  0.0066,  0.1306,  0.3476,  0.1613, -0.6285])</code></pre>
</div>
</div>
<p>These initial values are just random and by no means have any ground for being accurate, but they are a starting point to begin the method of gradient descent.</p>
<p>Here’s what that would look like:</p>
<p><img src="images/Gradient_Descent.png" alt="linear ML model outcome"></p>
<p>Cost simply put is performance while weight is the what coefficients you placed for each column that help determine the prediction.</p>
<p>To determine how much we incrementally step by, we need to create a loss function that calculates how much do we need to alter certain coefficients to hopefully improve the cost.</p>
<p>One of these ways is through mean absolute value of the calculated prediction - actual prediction as we see below</p>
<p>loss is the calculation of how close our model was to the target. In this case if the person survived or not.</p>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> torch.<span class="bu">abs</span>(preds<span class="op">-</span>t_dep).mean()</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>tensor(0.5382)</code></pre>
</div>
</div>
</section>
<section id="create-functions-to-automate-and-repeat-our-steps" class="level1">
<h1>Create functions to automate and repeat our steps</h1>
<p>These are past code snippets we ran, but now reusable since placed in a function block</p>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calc_preds(coeffs, indeps): <span class="cf">return</span> (indeps<span class="op">*</span>coeffs).<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calc_loss(coeffs, indeps, deps): <span class="cf">return</span> torch.<span class="bu">abs</span>(calc_preds(coeffs, indeps)<span class="op">-</span>deps).mean()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="doing-a-gradient-descent-step" class="level1">
<h1>Doing a gradient descent step</h1>
<p>Where does derivatives fit into our idea of gradient descent? It helps to determine in which direction the incremental step will go in. Based on last image above, it makes it seem obvious to know which direction to go in, but not all gradient descents are simply a U shape. Many will have tiny pockets and random bumps that will affect performance and the machine learning model needs to determine which way to head.</p>
<p>This function sums up the essence of the gradient descent algorithm and the missing piece that is solved in the next piece of code:</p>
<p><img src="images/Gradient_Descent_Formula.webp" alt="linear ML model outcome"></p>
<p>Since we are looking for what’s in red and we already know whats in blue. We also know what’s in green which is called a learning rate, Something we determine ourselves through trial and error. Now to calculate the derivatives will help determine our missing piece of whats in purple.</p>
<p>To calculate derivatives automatically, we can call requires_grad_() to perform that but any function with an (_) at the end will update the values</p>
<p>By calling requires_grad_() on the vector of coefficients, we state to the machine learning model that it is required to store the gradient values for each coefficient at each step. Almost like a recorded history of transactions, that way when we want to tweak the coefficients to get better performance, the model can see the long list of different changes we made and make better calculations.</p>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>coeffs.requires_grad_() <span class="co">#pytorch method</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625], requires_grad=True)</code></pre>
</div>
</div>
<p>By requiring that option, when calculating loss we gained the ability to attach the gradient function that stores the gradient values.</p>
<p>That gradient function is the key towards solving the purple section in the image above.</p>
<p>To get the result, the solution requires calculating the loss value to now use its value with the function we set to be required to calculate the direction of fastest increase.</p>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> calc_loss(coeffs, t_indep, t_dep)</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>tensor(0.5382, grad_fn=&lt;MeanBackward0&gt;)</code></pre>
</div>
</div>
<p>To call this function we call backward() that will calculate the coefficient gradient values into a variable called grad.</p>
<p>This is necessary because we want our model to learn how to improve its ability to get the correct answer, part of that is going backwards and determining which coefficients we should change and by how much to improve its performance. This is called backpropagation.</p>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>loss.backward()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="what-do-these-numbers-mean" class="level1">
<h1>What do these numbers mean?</h1>
<p>The result below of coeffs.grad show what gradient values (aka which coefficients need changing and by how much) for each coefficient used to calculate loss above.</p>
<p>Positive vs negative values determine which direction the improvement needs to be made while the model needs to determine which gradient values are the largest such that they will have the greatest impact on improving the model</p>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>coeffs.grad</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>tensor([-0.0106,  0.0129, -0.0041, -0.0484,  0.2099, -0.2132, -0.1212, -0.0247,  0.1425, -0.1886, -0.0191,  0.2043])</code></pre>
</div>
</div>
<p>Taking the gradient values we calculated through backpropagation and multiplying it by a learning rate we chose based on what we think is best will be subtracted from the current coefficients to create new coefficients to test.</p>
<p>The formula from the image above is what this next piece of code performs and this image below describes how this process flows to train our model:</p>
<p><img src="images/Simple_Learning_Algorithm.jpg" alt="linear ML model outcome"></p>
<p>If you now look at what the code block prints out, you will see that it has calculated the new loss value based on the new coefficients created.</p>
<p>Comparing the two: (old) 0.5382 &gt; (new)0.5197 shows that there was improvement in lowering the loss.</p>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>    coeffs.sub_(coeffs.grad <span class="op">*</span> <span class="fl">0.1</span>)</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(calc_loss(coeffs, t_indep, t_dep))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor(0.5197)</code></pre>
</div>
</div>
</section>
<section id="training-the-linear-model" class="level1">
<h1>Training the linear model</h1>
<p>Splitting your data for training and validation sets. We import a library that can split our data into these two sets via a random seed that we set.</p>
<p>For computers there is no real sense of randomness so us setting the seed will give it some sort of randomness.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.data.transforms <span class="im">import</span> RandomSplitter</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>trn_split,val_split<span class="op">=</span>RandomSplitter(seed<span class="op">=</span><span class="dv">42</span>)(df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The result of the split creates two variables that contain a list of indexes that are chosen for that specific set. The numbers you see printed below the code block are simply which numbers based on their row position were chosen.</p>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>val_split</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>(#178) [303,778,531,385,134,476,691,443,386,128...]</code></pre>
</div>
</div>
<p>Whats happening below:</p>
<ol type="1">
<li>creating the list of actual row of independent values needed by calling the original dataset and only extracting whats required for each set.</li>
<li>performing the same thing for the dependent variable in order to grade performance</li>
<li>Grabbing the length of the training and validation sets</li>
</ol>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>trn_indep,val_indep <span class="op">=</span> t_indep[trn_split],t_indep[val_split] <span class="co">#1</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>trn_dep,val_dep <span class="op">=</span> t_dep[trn_split],t_dep[val_split] <span class="co">#2</span></span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(trn_indep),<span class="bu">len</span>(val_indep) <span class="co">#3</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>(713, 178)</code></pre>
</div>
</div>
<p>Taking past code blocks and making them resusable.</p>
<p>The code function below makes the learning step reusable when training our linear model.</p>
<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> update_coeffs(coeffs, lr): </span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>    coeffs.sub_(coeffs.grad <span class="op">*</span> lr)</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>    coeffs.grad.zero_()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This function defines what an Epoch is in machine learning.</p>
<p>An epoch is when all the training data is used at once and is defined as the total number of iterations of all the training data in one cycle for training the machine learning model</p>
<p>In our case, its form calculating loss, performing backpropagation, and updating the coefficients through gradient descent and our learning rate.</p>
<div class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> one_epoch(coeffs, lr):</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> calc_loss(coeffs, trn_indep, trn_dep)</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad(): update_coeffs(coeffs, lr)</span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>loss<span class="sc">: .3f}</span><span class="ss">"</span>, end<span class="op">=</span><span class="st">"; "</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The function makes creating the inital random variables reusable and this time attaches that the coefficients require the gradient values</p>
<div class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> init_coeffs(): <span class="cf">return</span> (torch.rand(n_coeff)<span class="op">-</span><span class="fl">0.5</span>).requires_grad_()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This bulky function ties all the previous functions together in a reusable step by step process to train your linear model based on what we created before. - We set the amount of epochs/times we want to run this process - We set the learning rate to increment each time we update the coefficients</p>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_model(epochs<span class="op">=</span><span class="dv">30</span>, lr<span class="op">=</span><span class="fl">0.01</span>):</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>    torch.manual_seed(<span class="dv">434</span>)</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>    coeffs <span class="op">=</span> init_coeffs()</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(epochs): one_epoch(coeffs, lr <span class="op">=</span> lr)</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> coeffs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This is the product of all the functions we made by running to train the model on 18 epochs with a learning rate of 0.02</p>
<p>Our output shows what the loss value of each epoch and how it steadily dropped to its final result of .218</p>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>coeffs <span class="op">=</span> train_model(<span class="dv">18</span>, lr <span class="op">=</span><span class="fl">0.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> 0.595;  0.529;  0.477;  0.431;  0.385;  0.349;  0.325;  0.308;  0.299;  0.290;  0.314;  0.277;  0.303;  0.276;  0.290;  0.279;  0.287;  0.278; </code></pre>
</div>
</div>
</section>
<section id="successfully-build-and-trained-a-linear-model" class="level1">
<h1>Successfully Build and Trained a linear model</h1>
<p>The block below shows the loss for each coefficients. This gives insight how Age depending on how old, gave you less of a chance at surviving</p>
<div class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> show_coeffs(): <span class="cf">return</span> <span class="bu">dict</span>(<span class="bu">zip</span>(indep_cols, coeffs.requires_grad_(<span class="va">False</span>)))</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>show_coeffs()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>{'Age': tensor(-0.0526),
 'SibSp': tensor(0.0665),
 'Parch': tensor(-0.2101),
 'LogFare': tensor(-0.3478),
 'Sex_male': tensor(-0.1469),
 'Sex_female': tensor(0.7051),
 'Pclass_1': tensor(0.5845),
 'Pclass_2': tensor(0.4202),
 'Pclass_3': tensor(0.3393),
 'Embarked_C': tensor(0.0497),
 'Embarked_Q': tensor(0.1165),
 'Embarked_S': tensor(0.0920)}</code></pre>
</div>
</div>
</section>
<section id="measuring-accuracy" class="level1">
<h1>Measuring accuracy</h1>
<p>Mean absolute error as a performance measurement is great but not the only way to measure its performance.</p>
<p>Accuracy is another way to check for performance by first calculating the predictions like we did once before and storing it in preds</p>
<div class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> calc_preds(coeffs, val_indep)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This time we take the predictions we made and pass it through a if statement.</p>
<p>We then create a threshold saying if the predicition is higher than 0.5, then it is True otherwise False. ex. –&gt; (preds &gt; 0.5)</p>
<p>We then compare the validation set named val_dep that has been passed through bool() which converts the matrix of 0 and 1 into true and false. Comparing it to what prediction was accurately considered true or false based on the threshold.</p>
<div class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> val_dep.<span class="bu">bool</span>()<span class="op">==</span>(preds<span class="op">&gt;</span><span class="fl">0.5</span>)</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>results[:<span class="dv">16</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="44">
<pre><code>tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True, False, False, False,  True,  True, False])</code></pre>
</div>
</div>
<p>When we then convert the results matrix into a float so that pytorch can calculate it properly and take the mean we see that the accuracy of this model is .7921 or 79% accurate.</p>
<div class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>results.<span class="bu">float</span>().mean()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="45">
<pre><code>tensor(0.7921)</code></pre>
</div>
</div>
<p>This is now created as a resusable function to test accuracy</p>
<div class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> acc(coeffs): <span class="cf">return</span> (val_dep.<span class="bu">bool</span>()<span class="op">==</span>(calc_preds(coeffs, val_indep)<span class="op">&gt;</span><span class="fl">0.5</span>)).<span class="bu">float</span>().mean()</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>acc(coeffs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="46">
<pre><code>tensor(0.7921)</code></pre>
</div>
</div>
</section>
<section id="using-sigmoid" class="level1">
<h1>Using Sigmoid</h1>
<p>Looking back on the past predictions made, it shows how some predictions are represented with a negative value or greater than one which isn’t all too great when trying to calculate the rate of the dependent variable</p>
<div class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>preds[:<span class="dv">28</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="47">
<pre><code>tensor([1.0815, 0.1722, 0.1088, 0.1132, 0.2017, 0.1789, 0.9077, 1.0518, 0.0396, 0.8759, 0.1413, 0.0442, 0.1159, 1.0233, 0.1497, 0.3151,
        0.3020, 0.9821, 0.1559, 0.9894, 0.1468, 0.3079, 1.0240, 0.8905, 0.1550, 0.1216, 0.9699, 0.3039])</code></pre>
</div>
</div>
<p>Our solution for this problem would to import a mathmatical formula that could squish all possible numbers into a range of 0-1</p>
<p>The sigmoid function is the key to making that happen</p>
<div class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sympy</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>sympy.plot(<span class="st">"1/(1+exp(-x))"</span>, xlim<span class="op">=</span>(<span class="op">-</span><span class="dv">10</span>,<span class="dv">10</span>))<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="app_files/figure-html/cell-48-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="redefine-our-function" class="level1">
<h1>Redefine our function</h1>
<p>We take our prediction calculation function to now pass the result values through the sigmoid function above to make a more optimized result.</p>
<p>So that the bigger the number the closer to 1 while the smaller the number the closer its to 0</p>
<div class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calc_preds(coeffs, indeps): <span class="cf">return</span> torch.sigmoid((indeps<span class="op">*</span>coeffs).<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>When retraining the model, the predictions are more in-line between 0 and 1</p>
<div class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>coeffs <span class="op">=</span> train_model(lr<span class="op">=</span><span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> 0.550;  0.306;  0.209;  0.201;  0.200;  0.198;  0.198;  0.197;  0.197;  0.196;  0.196;  0.196;  0.196;  0.195;  0.195;  0.195;  0.195;  0.195;  0.195;  0.195;  0.195;  0.195;  0.194;  0.194;  0.194;  0.194;  0.194;  0.194;  0.194;  0.194; </code></pre>
</div>
</div>
<p>Integrating this sigmoid function will not affect the accuracy score at all. Since this dependent variable relies on a binary output, meaning whether survived is yes or no, the sigmoid function is almost necessary to ensure the best results</p>
<div class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>acc(coeffs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="51">
<pre><code>tensor(0.8258)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>show_coeffs()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">
<pre><code>{'Age': tensor(-1.1117),
 'SibSp': tensor(-1.2590),
 'Parch': tensor(-0.9966),
 'LogFare': tensor(-0.1989),
 'Sex_male': tensor(-8.6799),
 'Sex_female': tensor(7.9411),
 'Pclass_1': tensor(3.2276),
 'Pclass_2': tensor(2.4573),
 'Pclass_3': tensor(-5.6379),
 'Embarked_C': tensor(1.4539),
 'Embarked_Q': tensor(1.9777),
 'Embarked_S': tensor(-4.4705)}</code></pre>
</div>
</div>
</section>
<section id="improving-our-processes" class="level1">
<h1>Improving our processes:</h1>
</section>
<section id="using-matrix-product" class="level1">
<h1>Using matrix product</h1>
<p>This new symbol @ works similarly to * for Matrix multiplication except that the * is actually element wise multiplication to include broadcasting since it multiplies numbers corresponding to their position in the matrix.</p>
<p>The @ symbol is the original matrix multiplication that is now replacing the previous iteration that was val_indep*coeffs.sum(axis=1)</p>
<div class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>(val_indep<span class="op">*</span>coeffs).<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="53">
<pre><code>tensor([ 11.9600, -12.7427, -13.2647, -11.0806, -11.1246, -11.4215,   3.4503,   5.4547, -20.0446,   2.9996, -19.3028, -13.6098, -19.2470,
          3.8778, -19.3250, -10.6539, -10.9318,   5.3093, -11.3401,  -2.6705, -19.1915, -10.8067,  11.6067,   4.6378, -19.1327, -12.9338,
         -2.5843, -10.8901, -19.0969,   3.8782,   5.2615,  -3.6321, -19.1220, -19.2824,  11.8766,  -3.2676, -10.6893,  12.1535, -19.1921,
         -2.7419, -11.0350, -19.1921, -11.6375,  12.0393, -19.1365,  -3.6857, -19.2788, -19.4193, -12.7397,  -2.5403,  -4.5446, -20.1558,
        -19.9860, -19.2022, -11.1322, -11.2156, -12.7428, -19.5354, -19.1504, -19.2749,  -4.5224, -19.2485, -11.1440, -19.1499,   5.0540,
        -10.5197, -11.1107, -19.4331, -13.3088,   5.2173, -19.2193,   3.0025, -11.2017, -19.1968, -10.3613, -19.0799, -19.1921, -10.7520,
        -11.0412, -11.4346, -11.3054,  11.5061, -19.1776, -19.1891,   5.1553,  -5.7253,  -4.5558,   5.8612,  11.2032, -11.0968, -19.3043,
        -19.1921,  12.0566, -13.3480,   3.1698,  -5.3528, -11.4374,   3.5310,   3.9060, -12.6694, -19.4315,   3.8782, -19.3027, -19.2749,
        -10.6404, -11.3608, -19.2802,   4.9310,  -4.6474, -19.4152,   5.0321,  -2.8494, -10.3658,  12.3867, -19.1921,  11.4932,  -3.6037,
        -12.7428, -19.4407,  11.5858, -19.9244,  -5.2955, -12.7428,  -3.3094, -13.2646, -10.4353,  -2.5840,  -2.5982, -19.0856, -11.5669,
          6.3333, -19.3697,   5.1652,   5.3922,  11.9725, -19.1226, -11.5982, -19.2662,  -5.4873,   5.3430, -11.1941,  11.6032, -19.4798,
        -12.8539,  -3.2435,   5.5261, -19.3887,   2.9909,   6.1918,   2.8783,  -2.8261,   3.5460,   5.5582, -13.3554, -13.0900, -20.8487,
        -19.1921,  -2.6786, -11.2497, -19.2092,  12.1640,  -5.4361, -19.3762, -11.0655,  11.8007,   5.7637,   5.1476,   5.2601, -11.8117,
        -10.7971,  -3.1067, -19.1397,   6.1008, -19.1968, -19.4695,   5.7294, -10.3663, -19.3270])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>val_indep<span class="op">@</span>coeffs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="54">
<pre><code>tensor([ 11.9600, -12.7427, -13.2647, -11.0806, -11.1246, -11.4215,   3.4503,   5.4547, -20.0446,   2.9996, -19.3028, -13.6098, -19.2470,
          3.8778, -19.3250, -10.6539, -10.9318,   5.3093, -11.3401,  -2.6705, -19.1915, -10.8067,  11.6067,   4.6378, -19.1327, -12.9338,
         -2.5843, -10.8901, -19.0969,   3.8782,   5.2615,  -3.6321, -19.1220, -19.2824,  11.8766,  -3.2676, -10.6893,  12.1535, -19.1921,
         -2.7419, -11.0350, -19.1921, -11.6375,  12.0393, -19.1365,  -3.6857, -19.2788, -19.4193, -12.7397,  -2.5403,  -4.5446, -20.1558,
        -19.9860, -19.2022, -11.1322, -11.2156, -12.7428, -19.5354, -19.1504, -19.2749,  -4.5224, -19.2485, -11.1440, -19.1499,   5.0540,
        -10.5197, -11.1107, -19.4331, -13.3088,   5.2173, -19.2193,   3.0025, -11.2017, -19.1968, -10.3613, -19.0799, -19.1921, -10.7520,
        -11.0412, -11.4346, -11.3054,  11.5061, -19.1776, -19.1891,   5.1553,  -5.7253,  -4.5558,   5.8612,  11.2032, -11.0968, -19.3043,
        -19.1921,  12.0566, -13.3480,   3.1698,  -5.3528, -11.4374,   3.5310,   3.9060, -12.6694, -19.4315,   3.8782, -19.3027, -19.2749,
        -10.6404, -11.3608, -19.2802,   4.9310,  -4.6474, -19.4152,   5.0321,  -2.8494, -10.3658,  12.3867, -19.1921,  11.4932,  -3.6037,
        -12.7428, -19.4407,  11.5858, -19.9244,  -5.2955, -12.7428,  -3.3094, -13.2646, -10.4353,  -2.5840,  -2.5982, -19.0856, -11.5669,
          6.3333, -19.3697,   5.1652,   5.3922,  11.9725, -19.1226, -11.5982, -19.2662,  -5.4873,   5.3430, -11.1941,  11.6032, -19.4798,
        -12.8539,  -3.2435,   5.5261, -19.3887,   2.9909,   6.1918,   2.8783,  -2.8261,   3.5460,   5.5582, -13.3554, -13.0900, -20.8487,
        -19.1921,  -2.6786, -11.2497, -19.2092,  12.1640,  -5.4361, -19.3762, -11.0655,  11.8007,   5.7637,   5.1476,   5.2601, -11.8117,
        -10.7971,  -3.1067, -19.1397,   6.1008, -19.1968, -19.4695,   5.7294, -10.3663, -19.3270])</code></pre>
</div>
</div>
</section>
<section id="simplifying-function-we-had-before-to-implement-sigmoid" class="level1">
<h1>Simplifying function we had before to implement sigmoid</h1>
<div class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calc_preds(coeffs, indeps): <span class="cf">return</span> torch.sigmoid(indeps<span class="op">@</span>coeffs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Updating this one slightly to add not only an n_coeff length vector of coefficients, but now it is a matrix with its dimesnsions as n_coeff x 1</p>
<div class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> init_coeffs(): <span class="cf">return</span> (torch.rand(n_coeff, <span class="dv">1</span>)<span class="op">*</span><span class="fl">0.1</span>).requires_grad_()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>trn_dep and val_dep are technically vectors and not recognized as matrices. Because of this, performing matrix multiplication between a vector and a matrix will not produce a matrix.</p>
<p>Reformatting these vectors to matrices to have defined 1 “column” is really the same how a vector is just one column with a given amount of rows.</p>
<p>This format is only possible through the code syntax below as the key word None after the comma specifies that another row is needed but nothing will fill its space. This effectively makes a matrix equivalent to a vector. (Vectors are still technically matrices but computers are weird)</p>
<div class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>trn_dep <span class="op">=</span> trn_dep[:, <span class="va">None</span>]</span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>val_dep <span class="op">=</span> val_dep[:, <span class="va">None</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>trn_dep.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="58">
<pre><code>torch.Size([713, 1])</code></pre>
</div>
</div>
<p>Re-run our training model to test if our results stayed the same with this new change</p>
<div class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>coeffs <span class="op">=</span> train_model(lr<span class="op">=</span><span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> 0.517;  0.346;  0.301;  0.276;  0.261;  0.251;  0.245;  0.240;  0.236;  0.233;  0.231;  0.229;  0.227;  0.226;  0.225;  0.224;  0.223;  0.222;  0.221;  0.220;  0.219;  0.219;  0.218;  0.218;  0.217;  0.216;  0.216;  0.215;  0.215;  0.215; </code></pre>
</div>
</div>
<p>Noticed a slight increase in accuracy from the last run</p>
<div class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>acc(coeffs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="60">
<pre><code>tensor(0.8371)</code></pre>
</div>
</div>
<p>Taking note that since our vector change, the output of the coefficients has updated to also a matrix of 12 x 1</p>
<div class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>coeffs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="61">
<pre><code>tensor([[-0.4400],
        [-0.4568],
        [-0.2386],
        [ 0.1695],
        [-3.7836],
        [ 3.4341],
        [ 1.0979],
        [ 0.8266],
        [-2.1455],
        [ 0.3479],
        [ 0.5392],
        [-1.2166]], requires_grad=True)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="62">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>coeffs.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="62">
<pre><code>torch.Size([12, 1])</code></pre>
</div>
</div>
</section>
<section id="a-neural-network" class="level1">
<h1>A Neural Network</h1>
<p><img src="images/neural_network-1024x707.webp" alt="linear ML model outcome"></p>
<p>The image above is a visual representation of how a neural network works.</p>
<p>The input layer is just they way the computer hands the data to the first “hidden” layer.<br>
A layer is just those column/s of coefficients created randomly that will be tested, calculated for loss, updated and recalculated till deemed fit.<br>
What makes it “hidden” comes from not having to directly interact with it, but allowed to run behind the scenes.<br>
The image contains two hidden layers but anyone can increase the amount to what they require, that just means to create more rows of coefficients.</p>
<p>The more complex your data results in the more coefficients in your rows, the more factors in play for your dependent variable the more layers are needed. Of course increasing one aspect of the neural network will cause an increase in all aspects.</p>
<p>The function states that 20 columns of coefficients is specified for the hidden layers are going to be created(In this example its just one), the values for those 20 columns of coefficients are normalized by keeping their range between -0.5 to 0.5. To make sure the values also dont jump in value the next matrix multiplication, dividing by n_hidden keeps them low enough.</p>
<p>Layer 2 variable is there to create the coefficients needed to multiply against the matrix just created. This process is similar to this -&gt; torch.rand(n_coeff, 1)<em>0.1).requires_grad_() where torch.rand(n_coeff,1) is now what layer 1 variable is doing while the </em>0.1 now needs to be handled by layer 2.</p>
<p>With all neural networks is customary to create a random constant term to ensure some sort of result is outputted in case of error so the const variable is created as a scalar vector</p>
<div class="cell" data-execution_count="63">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> init_coeffs(n_hidden<span class="op">=</span><span class="dv">20</span>):</span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a>    layer1 <span class="op">=</span> (torch.rand(n_coeff, n_hidden)<span class="op">-</span><span class="fl">0.5</span>)<span class="op">/</span>n_hidden <span class="co"># based on image, process is input layer to hidden layers</span></span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a>    layer2 <span class="op">=</span> torch.rand(n_hidden, <span class="dv">1</span>)<span class="op">-</span><span class="fl">0.3</span> <span class="co"># based on the image, process leads from the hidden layers to one output</span></span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a>    const <span class="op">=</span> torch.rand(<span class="dv">1</span>)[<span class="dv">0</span>]</span>
<span id="cb100-5"><a href="#cb100-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> layer1.requires_grad_(),layer2.requires_grad_(),const.requires_grad_() <span class="co"># returns a tuple - a list of values that are finite and unable to be changed</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>If above did not make much sense, the update to the next method explains better on how the process now works.</p>
<p>This is what calc_preds(coeffs, indeps) did previously:</p>
<pre><code>def calc_preds(coeffs, indeps): return torch.sigmoid(indeps@coeffs)
</code></pre>
<p>The process for matrix multiplication is slightly more complicated than just mutliplying a single column of coefficients to the independent variable matrix.<br>
Now the process within calc_preds goes in this order: - separate the output of coeffs into three variables of l2, l2, const. (these correspond to the order that is outputted by init_coeffs above) - the result variable is created and now the first matrix multiplication begins with the independent variable matrix and layer 1 and its hidden layers (also relu() replaces any negatives with zeros since its the activiation function) - Now perform the second matrix mutliply for the final layer of the neural network to output a single value and add it with the const - apply sigmoid to balance it and return its accuracy.</p>
<div class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb102-3"><a href="#cb102-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calc_preds(coeffs, indeps):</span>
<span id="cb102-4"><a href="#cb102-4" aria-hidden="true" tabindex="-1"></a>    l1,l2,const <span class="op">=</span> coeffs</span>
<span id="cb102-5"><a href="#cb102-5" aria-hidden="true" tabindex="-1"></a>    res <span class="op">=</span> F.relu(indeps<span class="op">@</span>l1)</span>
<span id="cb102-6"><a href="#cb102-6" aria-hidden="true" tabindex="-1"></a>    res <span class="op">=</span> res<span class="op">@</span>l2 <span class="op">+</span> const</span>
<span id="cb102-7"><a href="#cb102-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> torch.sigmoid(res)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The code above executes the bulk of what an epoch would perform and now the newly updated update_coeffs function has to account for multiple columns considered as layers to be updated based on what their gradient values were calculated as, then all are then multiplied by a specified learning rate.</p>
<p>consider this process as a whole rather than individual parts because its essentially the same as how it was performed previously with only one column of coefficients.</p>
<div class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> update_coeffs(coeffs, lr):</span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> layer <span class="kw">in</span> coeffs: </span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a>        layer.sub_(layer.grad <span class="op">*</span> lr)</span>
<span id="cb103-4"><a href="#cb103-4" aria-hidden="true" tabindex="-1"></a>        layer.grad.zero_()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>train_model needed no update to keep up with its counterparts since train_model only provides the order of operations for other functions</p>
<div class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a>coeffs <span class="op">=</span> train_model(epochs<span class="op">=</span> <span class="dv">50</span>,lr<span class="op">=</span><span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> 0.560;  0.546;  0.532;  0.509;  0.480;  0.442;  0.390;  0.330;  0.285;  0.260;  0.245;  0.236;  0.230;  0.226;  0.223;  0.221;  0.219;  0.217;  0.215;  0.214;  0.212;  0.211;  0.210;  0.209;  0.208;  0.207;  0.206;  0.206;  0.205;  0.204;  0.204;  0.203;  0.203;  0.202;  0.202;  0.201;  0.201;  0.201;  0.200;  0.200;  0.200;  0.199;  0.199;  0.199;  0.199;  0.198;  0.198;  0.198;  0.198;  0.198; </code></pre>
</div>
</div>
<p>From the training it appears that despite upgrading from a linear model to neural network that the accuracy has not improved. This may happen from tim to time and for a number of factors. In this case the dataset is very small and simple so the neural network cannot be fully utilized. On top of that, it affects how small our validation set to calculate accuracy so that also comes into play.</p>
<div class="cell" data-execution_count="67">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a>acc(coeffs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="67">
<pre><code>tensor(0.8258)</code></pre>
</div>
</div>
</section>
<section id="deep-learning" class="level1">
<h1>Deep Learning</h1>
<p>We are increasing the hidden layers from just one, to n number of layers</p>
<div class="cell" data-execution_count="68">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> init_coeffs():</span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a>    hiddens <span class="op">=</span> [<span class="dv">10</span>, <span class="dv">10</span>] <span class="co"># &lt;- set this to the size of each hidden layer that you would want</span></span>
<span id="cb108-3"><a href="#cb108-3" aria-hidden="true" tabindex="-1"></a>    sizes <span class="op">=</span> [n_coeff] <span class="op">+</span> hiddens <span class="op">+</span> [<span class="dv">1</span>] <span class="co"># sizes now equals the number of required coefficients + the number of hidden layers set + 1 creating the new matrix</span></span>
<span id="cb108-4"><a href="#cb108-4" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(sizes) <span class="co"># Gets the new length based on new hidden layer requirements</span></span>
<span id="cb108-5"><a href="#cb108-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(n)</span>
<span id="cb108-6"><a href="#cb108-6" aria-hidden="true" tabindex="-1"></a>    layers <span class="op">=</span> [(torch.rand(sizes[i], sizes[i<span class="op">+</span><span class="dv">1</span>])<span class="op">-</span><span class="fl">0.5</span>)<span class="op">/</span>sizes[i<span class="op">+</span><span class="dv">1</span>]<span class="op">*</span><span class="dv">4</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n<span class="op">-</span><span class="dv">1</span>)] <span class="co"># calculate based on the range between 0 to n-1, the random number generated from (index at i and i + 1) - 0.3 / index i +1*4</span></span>
<span id="cb108-7"><a href="#cb108-7" aria-hidden="true" tabindex="-1"></a>    consts <span class="op">=</span> [(torch.rand(<span class="dv">1</span>)[<span class="dv">0</span>]<span class="op">-</span><span class="fl">0.5</span>)<span class="op">*</span><span class="fl">0.1</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n<span class="op">-</span><span class="dv">1</span>)]</span>
<span id="cb108-8"><a href="#cb108-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> l <span class="kw">in</span> layers<span class="op">+</span>consts: l.requires_grad_()</span>
<span id="cb108-9"><a href="#cb108-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> layers,consts</span>
<span id="cb108-10"><a href="#cb108-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-11"><a href="#cb108-11" aria-hidden="true" tabindex="-1"></a>init_coeffs()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>4</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="68">
<pre><code>([tensor([[     0.0597,     -0.1089,     -0.1872,      0.1503,      0.0349,      0.0843,      0.0638,     -0.1305,      0.0323,      0.1657],
          [    -0.1835,      0.0139,     -0.1497,      0.0631,     -0.1032,      0.1773,      0.0145,     -0.1507,      0.0144,     -0.0591],
          [     0.0761,     -0.1209,      0.0845,     -0.0227,      0.1019,      0.0859,     -0.1904,     -0.1003,      0.1576,     -0.1862],
          [     0.0196,      0.0991,      0.0810,      0.0736,     -0.0344,     -0.1892,      0.0950,     -0.1968,     -0.1044,      0.1909],
          [     0.0753,      0.0645,      0.0397,     -0.0046,      0.1985,     -0.1713,     -0.1519,      0.1284,     -0.0721,      0.0447],
          [    -0.1499,      0.1185,     -0.1389,     -0.1115,     -0.1626,      0.0146,      0.0188,     -0.1037,      0.1803,     -0.1398],
          [     0.1310,     -0.0644,      0.0780,     -0.1676,     -0.1036,     -0.1120,     -0.1389,      0.0547,     -0.1469,     -0.1534],
          [    -0.0186,      0.1257,      0.1910,     -0.0328,     -0.1038,     -0.1527,      0.1772,     -0.1342,     -0.0898,      0.0461],
          [    -0.1970,      0.0890,     -0.1757,     -0.1046,      0.0056,      0.1944,     -0.1124,      0.0714,     -0.1206,      0.0933],
          [    -0.0855,      0.1765,      0.0851,      0.0001,     -0.1860,      0.0577,      0.1914,     -0.1655,     -0.0193,      0.1295],
          [    -0.0444,     -0.1326,      0.0630,     -0.1239,     -0.0815,      0.0856,      0.1507,      0.1745,     -0.0750,      0.0618],
          [    -0.0534,      0.1719,      0.0882,     -0.0588,     -0.1874,     -0.0470,     -0.1594,      0.0834,      0.0360,      0.1769]],
         requires_grad=True),
  tensor([[ 0.1724, -0.0702,  0.0243,  0.0471, -0.1346, -0.1407,  0.1660,  0.1016,  0.1028,  0.1671],
          [-0.1660, -0.0066, -0.1511,  0.0499,  0.0201,  0.0989, -0.0268, -0.1190,  0.1915,  0.0381],
          [ 0.0775, -0.1598,  0.1677, -0.0895, -0.1113, -0.1861, -0.0209, -0.1794,  0.1537,  0.1242],
          [ 0.0836, -0.1752,  0.0202,  0.1611, -0.1725, -0.0743, -0.0110,  0.1002, -0.0419, -0.1257],
          [ 0.1916,  0.0252, -0.0143, -0.0429,  0.1189, -0.1689, -0.0217, -0.0327, -0.0476, -0.0554],
          [-0.0782,  0.0142,  0.1227, -0.1895,  0.0983,  0.1253, -0.1096,  0.1520, -0.1533, -0.0171],
          [ 0.1232, -0.0769,  0.1147,  0.0434, -0.1001, -0.0856,  0.0040, -0.1797, -0.1234,  0.0482],
          [ 0.0928, -0.1340,  0.0250, -0.0523, -0.1330, -0.1020, -0.0126,  0.0932,  0.0729,  0.0328],
          [-0.0443, -0.0949, -0.1187,  0.1820,  0.1322, -0.0202, -0.1303, -0.0433, -0.0900,  0.0037],
          [ 0.0667,  0.0303, -0.1822, -0.1658,  0.1213, -0.1328,  0.0278,  0.0908,  0.1326,  0.0012]], requires_grad=True),
  tensor([[-0.0583],
          [-0.8540],
          [-1.9057],
          [-1.7072],
          [-0.4921],
          [-0.3238],
          [-1.8022],
          [ 1.4369],
          [-0.3649],
          [-0.0357]], requires_grad=True)],
 [tensor(-0.0441, requires_grad=True),
  tensor(-0.0187, requires_grad=True),
  tensor(0.0286, requires_grad=True)])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb111-2"><a href="#cb111-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-3"><a href="#cb111-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calc_preds(coeffs, indeps):</span>
<span id="cb111-4"><a href="#cb111-4" aria-hidden="true" tabindex="-1"></a>    layers, consts <span class="op">=</span> coeffs</span>
<span id="cb111-5"><a href="#cb111-5" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(layers)</span>
<span id="cb111-6"><a href="#cb111-6" aria-hidden="true" tabindex="-1"></a>    res <span class="op">=</span> indeps</span>
<span id="cb111-7"><a href="#cb111-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, l <span class="kw">in</span> <span class="bu">enumerate</span>(layers): <span class="co"># loops all the layers of the matrix</span></span>
<span id="cb111-8"><a href="#cb111-8" aria-hidden="true" tabindex="-1"></a>        res <span class="op">=</span> res<span class="op">@</span>l <span class="op">+</span> consts[i]  <span class="co"># performs matrix multiplication then adds the constant</span></span>
<span id="cb111-9"><a href="#cb111-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i<span class="op">!=</span> n<span class="op">-</span><span class="dv">1</span>: res <span class="op">=</span> F.relu(res) <span class="co"># perform relu as long as its not the last layer</span></span>
<span id="cb111-10"><a href="#cb111-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> torch.sigmoid(res) <span class="co"># if last layer then perform the final sigmoid function</span></span>
<span id="cb111-11"><a href="#cb111-11" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="70">
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="co"># After training the coefficients need to be updated based on their work</span></span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> update_coeffs(coeffs, lr):</span>
<span id="cb112-3"><a href="#cb112-3" aria-hidden="true" tabindex="-1"></a>    layers,consts <span class="op">=</span> coeffs</span>
<span id="cb112-4"><a href="#cb112-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> layer <span class="kw">in</span> layers<span class="op">+</span>consts: layer.sub_(layer.grad <span class="op">*</span> lr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="71">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a>coeffs <span class="op">=</span> train_model(lr<span class="op">=</span><span class="fl">1.4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>4
 0.514;  0.496;  0.486;  0.471;  0.453;  0.434;  0.416;  0.403;  0.393;  0.387;  0.384;  0.381;  0.380;  0.380;  0.379;  0.379;  0.379;  0.379;  0.379;  0.379;  0.379;  0.379;  0.379;  0.379;  0.379;  0.379;  0.379;  0.379;  0.379;  0.379; </code></pre>
</div>
</div>
<div class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a>acc(coeffs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="72">
<pre><code>tensor(0.5955)</code></pre>
</div>
</div>
<p>Stopped at 1:09:48</p>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>